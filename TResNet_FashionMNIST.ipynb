{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoudeepGhoshal/TResNet/blob/main/TResNet_FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmf6hf7gcD5C"
      },
      "source": [
        "# FashionMNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcBftLaNcG_b"
      },
      "source": [
        "## ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kNbaU6Sb9_k",
        "outputId": "4cb21e51-ffb6-4119-ba47-225d2b45980e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Reproducibility seed: 42\n",
            "Downloading Fashion-MNIST dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 209kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.88MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.9MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset splits - Train: 49000, Val: 10500, Test: 10500, Total: 70000\n",
            "\n",
            "--- Starting Training ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100 | Time: 37.20s | Train Loss: 0.8211, Train Acc: 68.14% | Val Loss: 0.9654, Val Acc: 70.69%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/100 | Time: 35.48s | Train Loss: 0.6319, Train Acc: 75.58% | Val Loss: 1.3289, Val Acc: 59.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/100 | Time: 38.35s | Train Loss: 0.5634, Train Acc: 78.17% | Val Loss: 0.9965, Val Acc: 67.43%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/100 | Time: 36.58s | Train Loss: 0.5365, Train Acc: 79.55% | Val Loss: 0.8998, Val Acc: 70.22%\n",
            "\n",
            "Reducing learning rate from 1.00e-03 to 2.00e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/100 | Time: 36.96s | Train Loss: 0.4504, Train Acc: 82.75% | Val Loss: 0.8591, Val Acc: 71.18%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/100 | Time: 35.53s | Train Loss: 0.4308, Train Acc: 83.48% | Val Loss: 0.9394, Val Acc: 71.07%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/100 | Time: 36.30s | Train Loss: 0.4200, Train Acc: 83.98% | Val Loss: 1.0087, Val Acc: 67.10%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/100 | Time: 36.50s | Train Loss: 0.4159, Train Acc: 84.17% | Val Loss: 0.9893, Val Acc: 67.06%\n",
            "\n",
            "Reducing learning rate from 2.00e-04 to 4.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/100 | Time: 36.53s | Train Loss: 0.3898, Train Acc: 85.28% | Val Loss: 1.1485, Val Acc: 64.47%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/100 | Time: 35.98s | Train Loss: 0.3767, Train Acc: 85.62% | Val Loss: 1.1864, Val Acc: 64.04%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/100 | Time: 35.70s | Train Loss: 0.3797, Train Acc: 85.61% | Val Loss: 1.1853, Val Acc: 63.97%\n",
            "\n",
            "Reducing learning rate from 4.00e-05 to 8.00e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/100 | Time: 35.76s | Train Loss: 0.3692, Train Acc: 85.96% | Val Loss: 1.1760, Val Acc: 64.18%\n",
            "\n",
            "Early stopping at epoch 12\n",
            "Restored model weights from the end of the best epoch: 5\n",
            "--- Training Finished ---\n",
            "\n",
            "--- Starting Comprehensive Evaluation on Test Set ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 83/83 [00:02<00:00, 33.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Top-K Accuracy Results ---\n",
            "Top-1 Accuracy: 64.11%\n",
            "Top-3 Accuracy: 92.21%\n",
            "Top-5 Accuracy: 98.06%\n",
            "\n",
            "--- Additional Performance Metrics ---\n",
            "Macro Average Precision: 0.6621\n",
            "Macro Average Recall: 0.6361\n",
            "Macro Average F1-Score: 0.5852\n",
            "Weighted Average Precision: 0.6623\n",
            "Weighted Average Recall: 0.6411\n",
            "Weighted Average F1-Score: 0.5890\n",
            "\n",
            "--- Model Confidence & Calibration Metrics ---\n",
            "Average Prediction Confidence: 0.8345\n",
            "Confidence Standard Deviation: 0.1993\n",
            "Average Prediction Entropy: 0.4496\n",
            "Expected Calibration Error: 0.1934\n",
            "\n",
            "Final Test Loss: 1.1664\n",
            "===============================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "CONFIG = {\n",
        "    \"batch_size\": 128,\n",
        "    \"num_epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"split_seed\": 42,\n",
        "    \"train_split\": 0.70,\n",
        "    \"val_split\": 0.15,\n",
        "    \"test_split\": 0.15,\n",
        "    \"num_classes\": 10,  # Fashion-MNIST has 10 classes\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"checkpoint_path\": \"./best_model.pth\",\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# Callback Classes\n",
        "# ==========================================\n",
        "\n",
        "class Callback:\n",
        "    \"\"\"Base callback class\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_training_end(self):\n",
        "        pass\n",
        "\n",
        "class ReduceLROnPlateau(Callback):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving\"\"\"\n",
        "    def __init__(self, optimizer, monitor='val_accuracy', factor=0.2, patience=3, min_lr=1e-7, verbose=1):\n",
        "        self.optimizer = optimizer\n",
        "        self.monitor = monitor\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                old_lr = self.optimizer.param_groups[0]['lr']\n",
        "                new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "                if new_lr != old_lr:\n",
        "                    self.optimizer.param_groups[0]['lr'] = new_lr\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nReducing learning rate from {old_lr:.2e} to {new_lr:.2e}\")\n",
        "                    self.wait = 0\n",
        "\n",
        "class EarlyStopping(Callback):\n",
        "    \"\"\"Stop training when a monitored metric has stopped improving\"\"\"\n",
        "    def __init__(self, monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1):\n",
        "        self.monitor = monitor\n",
        "        self.patience = patience\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.best_weights = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None:\n",
        "            return False\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return False\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def on_training_end(self, model=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose:\n",
        "            print(f\"Restored model weights from the end of the best epoch: {self.stopped_epoch + 1 - self.patience}\")\n",
        "        if model is not None and self.restore_best_weights and self.best_weights is not None:\n",
        "            model.load_state_dict(self.best_weights)\n",
        "\n",
        "class ModelCheckpoint(Callback):\n",
        "    \"\"\"Save the model after every epoch\"\"\"\n",
        "    def __init__(self, filepath, save_best_only=True, monitor='val_accuracy', verbose=1):\n",
        "        self.filepath = filepath\n",
        "        self.save_best_only = save_best_only\n",
        "        self.monitor = monitor\n",
        "        self.verbose = verbose\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None or model is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if not self.save_best_only:\n",
        "            filepath = self.filepath.replace('.pth', f'_epoch_{epoch + 1}.pth')\n",
        "            torch.save(model.state_dict(), filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "\n",
        "# ==========================================\n",
        "# Data Preprocessing\n",
        "# ==========================================\n",
        "\n",
        "def get_dataloaders(config):\n",
        "    \"\"\"Downloads, prepares, and splits Fashion-MNIST data, returning DataLoaders.\"\"\"\n",
        "\n",
        "    # Data augmentation for training\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=10),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.2860], std=[0.3530]),  # Fashion-MNIST specific normalization\n",
        "    ])\n",
        "\n",
        "    # No augmentation for validation/test\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.2860], std=[0.3530]),  # Fashion-MNIST specific normalization\n",
        "    ])\n",
        "\n",
        "    # Download Fashion-MNIST dataset\n",
        "    print(\"Downloading Fashion-MNIST dataset...\")\n",
        "    train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    test_dataset_original = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=test_transform\n",
        "    )\n",
        "\n",
        "    # Combine train and test datasets for custom splitting\n",
        "    # We need to apply the same transform to the combined dataset for consistency\n",
        "    combined_train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=False,\n",
        "        transform=test_transform  # Use test transform for consistent splitting\n",
        "    )\n",
        "\n",
        "    full_dataset = torch.utils.data.ConcatDataset([combined_train_dataset, test_dataset_original])\n",
        "\n",
        "    # Ensure reproducible splits\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(config[\"train_split\"] * total_size)\n",
        "    val_size = int(config[\"val_split\"] * total_size)\n",
        "    test_size = int(config[\"test_split\"] * total_size)\n",
        "\n",
        "    # Adjust sizes to ensure they sum to total_size (handle rounding issues)\n",
        "    actual_total = train_size + val_size + test_size\n",
        "    if actual_total != total_size:\n",
        "        # Add/subtract the difference to test_size\n",
        "        test_size += (total_size - actual_total)\n",
        "\n",
        "    print(f\"Dataset splits - Train: {train_size}, Val: {val_size}, Test: {test_size}, Total: {total_size}\")\n",
        "\n",
        "    # Create reproducible generator for splitting\n",
        "    generator = torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    train_subset, val_subset, test_subset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size], generator=generator\n",
        "    )\n",
        "\n",
        "    # Create a custom dataset class to apply different transforms to train subset\n",
        "    class TransformSubset(Dataset):\n",
        "        def __init__(self, subset, transform=None):\n",
        "            self.subset = subset\n",
        "            self.transform = transform\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            x, y = self.subset[index]\n",
        "            if self.transform:\n",
        "                # Convert tensor back to PIL Image for transforms\n",
        "                if isinstance(x, torch.Tensor):\n",
        "                    x = transforms.ToPILImage()(x)\n",
        "                x = self.transform(x)\n",
        "            return x, y\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.subset)\n",
        "\n",
        "    # Apply training transforms to training subset\n",
        "    train_subset_with_augment = TransformSubset(train_subset, train_transform)\n",
        "\n",
        "    # Set worker init function for reproducible DataLoader behavior\n",
        "    def worker_init_fn(worker_id):\n",
        "        np.random.seed(config[\"split_seed\"] + worker_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset_with_augment,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# ==========================================\n",
        "# Model Architecture and Training\n",
        "# ==========================================\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"A residual block, the fundamental building block of ResNet.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        # Main path\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut path (for matching dimensions)\n",
        "        self.downsample = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.downsample(x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"A modular ResNet implementation.\"\"\"\n",
        "    def __init__(self, block, layers, num_classes=200):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for s in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, s))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def ResNet18(num_classes=200):\n",
        "    return ResNet(ResidualBlock, [2, 2, 2, 2], num_classes)\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, config):\n",
        "    \"\"\"Main training loop with callbacks.\"\"\"\n",
        "    device = config[\"device\"]\n",
        "    model.to(device)\n",
        "\n",
        "    # Set seeds for reproducible training\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(config[\"split_seed\"])\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "    # Initialize callbacks\n",
        "    callbacks = [\n",
        "        ReduceLROnPlateau(\n",
        "            optimizer=optimizer,\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=7,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=config[\"checkpoint_path\"],\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        running_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\", leave=False)\n",
        "        for images, labels in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_loss / train_total\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['num_epochs']} | Time: {time.time() - start_time:.2f}s | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Prepare logs for callbacks\n",
        "        logs = {\n",
        "            'train_loss': train_loss,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc\n",
        "        }\n",
        "\n",
        "        # Execute callbacks\n",
        "        for callback in callbacks:\n",
        "            if isinstance(callback, EarlyStopping):\n",
        "                if callback.on_epoch_end(epoch, logs, model):\n",
        "                    early_stop = True\n",
        "                    break\n",
        "            elif isinstance(callback, ModelCheckpoint):\n",
        "                callback.on_epoch_end(epoch, logs, model)\n",
        "            else:\n",
        "                callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    # Execute callback cleanup\n",
        "    for callback in callbacks:\n",
        "        if isinstance(callback, EarlyStopping):\n",
        "            callback.on_training_end(model)\n",
        "        else:\n",
        "            callback.on_training_end()\n",
        "\n",
        "    print(\"--- Training Finished ---\\n\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "\n",
        "def calculate_top_k_accuracy(outputs, labels, k_values=[1, 3, 5]):\n",
        "    \"\"\"Calculate top-k accuracy for given k values.\"\"\"\n",
        "    batch_size = labels.size(0)\n",
        "    _, pred = outputs.topk(max(k_values), 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "    top_k_accuracies = {}\n",
        "    for k in k_values:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        top_k_accuracies[k] = correct_k.item() / batch_size\n",
        "\n",
        "    return top_k_accuracies\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "    \"\"\"Calculate entropy of probability distributions.\"\"\"\n",
        "    # Add small epsilon to avoid log(0)\n",
        "    epsilon = 1e-8\n",
        "    probs = probs + epsilon\n",
        "    entropy = -torch.sum(probs * torch.log(probs), dim=1)\n",
        "    return entropy\n",
        "\n",
        "def calculate_ece(confidences, accuracies, n_bins=10):\n",
        "    \"\"\"Calculate Expected Calibration Error.\"\"\"\n",
        "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers = bin_boundaries[:-1]\n",
        "    bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    ece = 0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower.item()) & (confidences <= bin_upper.item())\n",
        "        prop_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prop_in_bin.item() > 0:\n",
        "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece.item()\n",
        "\n",
        "def comprehensive_evaluation(model, test_loader, criterion, device):\n",
        "    \"\"\"Comprehensive evaluation with all requested metrics.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_confidences = []\n",
        "    all_entropies = []\n",
        "    all_top_k_results = {1: [], 3: [], 5: []}\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Convert outputs to probabilities\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Get predictions and confidences\n",
        "            confidences, predictions = torch.max(probs, dim=1)\n",
        "\n",
        "            # Calculate entropy\n",
        "            entropies = calculate_entropy(probs)\n",
        "\n",
        "            # Calculate top-k accuracies\n",
        "            top_k_accs = calculate_top_k_accuracy(outputs, labels, [1, 3, 5])\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_entropies.extend(entropies.cpu().numpy())\n",
        "\n",
        "            for k in [1, 3, 5]:\n",
        "                all_top_k_results[k].extend([top_k_accs[k]] * labels.size(0))\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_confidences = np.array(all_confidences)\n",
        "    all_entropies = np.array(all_entropies)\n",
        "\n",
        "    # Calculate basic metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    # Calculate top-k accuracies\n",
        "    top1 = np.mean([pred == label for pred, label in zip(all_predictions, all_labels)])\n",
        "    top3 = np.mean(all_top_k_results[3])\n",
        "    top5 = np.mean(all_top_k_results[5])\n",
        "\n",
        "    # Calculate precision, recall, f1-score\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate confidence and calibration metrics\n",
        "    avg_confidence = np.mean(all_confidences)\n",
        "    std_confidence = np.std(all_confidences)\n",
        "    avg_entropy = np.mean(all_entropies)\n",
        "\n",
        "    # Calculate ECE\n",
        "    accuracies = (all_predictions == all_labels).astype(float)\n",
        "    ece = calculate_ece(torch.tensor(all_confidences), torch.tensor(accuracies))\n",
        "\n",
        "    return {\n",
        "        'test_loss': avg_loss,\n",
        "        'top1': top1,\n",
        "        'top3': top3,\n",
        "        'top5': top5,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_weighted': precision_weighted,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'std_confidence': std_confidence,\n",
        "        'avg_entropy': avg_entropy,\n",
        "        'ece': ece\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# Main Execution\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set global seeds for full reproducibility\n",
        "    torch.manual_seed(CONFIG[\"split_seed\"])\n",
        "    np.random.seed(CONFIG[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(CONFIG[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(CONFIG[\"split_seed\"])\n",
        "        # Ensure deterministic behavior on CUDA\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"Using device: {CONFIG['device']}\")\n",
        "    print(f\"Reproducibility seed: {CONFIG['split_seed']}\")\n",
        "\n",
        "    # Get data loaders\n",
        "    dataloaders = get_dataloaders(CONFIG)\n",
        "    if dataloaders is None:\n",
        "        print(\"Could not prepare data. Halting execution.\", file=sys.stderr)\n",
        "        sys.exit(1) # Exit if data preparation failed\n",
        "\n",
        "    train_loader, val_loader, test_loader = dataloaders\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = ResNet18(num_classes=CONFIG[\"num_classes\"])\n",
        "    trained_model = train_and_validate(model, train_loader, val_loader, CONFIG)\n",
        "\n",
        "    # Comprehensive evaluation on the test set\n",
        "    print(\"--- Starting Comprehensive Evaluation on Test Set ---\")\n",
        "    results = comprehensive_evaluation(trained_model, test_loader, nn.CrossEntropyLoss(), CONFIG[\"device\"])\n",
        "\n",
        "    # Print all requested metrics\n",
        "    print(\"\\n--- Top-K Accuracy Results ---\")\n",
        "    print(f\"Top-1 Accuracy: {results['top1'] * 100:.2f}%\")\n",
        "    print(f\"Top-3 Accuracy: {results['top3'] * 100:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {results['top5'] * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Additional Performance Metrics ---\")\n",
        "    print(f\"Macro Average Precision: {results['precision_macro']:.4f}\")\n",
        "    print(f\"Macro Average Recall: {results['recall_macro']:.4f}\")\n",
        "    print(f\"Macro Average F1-Score: {results['f1_macro']:.4f}\")\n",
        "    print(f\"Weighted Average Precision: {results['precision_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average Recall: {results['recall_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average F1-Score: {results['f1_weighted']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Model Confidence & Calibration Metrics ---\")\n",
        "    print(f\"Average Prediction Confidence: {results['avg_confidence']:.4f}\")\n",
        "    print(f\"Confidence Standard Deviation: {results['std_confidence']:.4f}\")\n",
        "    print(f\"Average Prediction Entropy: {results['avg_entropy']:.4f}\")\n",
        "    print(f\"Expected Calibration Error: {results['ece']:.4f}\")\n",
        "\n",
        "    print(f\"\\nFinal Test Loss: {results['test_loss']:.4f}\")\n",
        "    print(\"===============================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU9FvvBvcKiq"
      },
      "source": [
        "## Hybrid Transformer on ResNet-18 (No PE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v6XZOm6KcNmt",
        "outputId": "0bcdb233-c21e-4a44-fe6c-ad90daaf6766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Reproducibility seed: 42\n",
            "Downloading Fashion-MNIST dataset...\n",
            "Dataset splits - Train: 49000, Val: 10500, Test: 10500, Total: 70000\n",
            "\n",
            "--- Starting Training ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100 | Time: 37.67s | Train Loss: 1.0263, Train Acc: 61.12% | Val Loss: 0.9385, Val Acc: 66.16%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/100 | Time: 37.92s | Train Loss: 0.6991, Train Acc: 73.08% | Val Loss: 0.9783, Val Acc: 67.68%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/100 | Time: 38.18s | Train Loss: 0.6030, Train Acc: 77.08% | Val Loss: 0.7202, Val Acc: 74.25%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/100 | Time: 38.28s | Train Loss: 0.5615, Train Acc: 78.61% | Val Loss: 0.7727, Val Acc: 72.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/100 | Time: 38.49s | Train Loss: 0.5274, Train Acc: 80.18% | Val Loss: 0.7936, Val Acc: 71.05%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/100 | Time: 38.19s | Train Loss: 0.5024, Train Acc: 80.96% | Val Loss: 0.8446, Val Acc: 72.76%\n",
            "\n",
            "Reducing learning rate from 1.00e-03 to 2.00e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/100 | Time: 38.03s | Train Loss: 0.4356, Train Acc: 83.49% | Val Loss: 0.7978, Val Acc: 72.15%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/100 | Time: 38.28s | Train Loss: 0.4181, Train Acc: 84.26% | Val Loss: 0.8376, Val Acc: 71.57%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/100 | Time: 38.42s | Train Loss: 0.4125, Train Acc: 84.50% | Val Loss: 0.9297, Val Acc: 69.26%\n",
            "\n",
            "Reducing learning rate from 2.00e-04 to 4.00e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/100 | Time: 38.87s | Train Loss: 0.3925, Train Acc: 85.11% | Val Loss: 0.9021, Val Acc: 70.37%\n",
            "\n",
            "Early stopping at epoch 10\n",
            "Restored model weights from the end of the best epoch: 3\n",
            "--- Training Finished ---\n",
            "\n",
            "--- Starting Comprehensive Evaluation on Test Set ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 83/83 [00:03<00:00, 27.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Top-K Accuracy Results ---\n",
            "Top-1 Accuracy: 70.41%\n",
            "Top-3 Accuracy: 95.80%\n",
            "Top-5 Accuracy: 99.12%\n",
            "\n",
            "--- Additional Performance Metrics ---\n",
            "Macro Average Precision: 0.7426\n",
            "Macro Average Recall: 0.6979\n",
            "Macro Average F1-Score: 0.6469\n",
            "Weighted Average Precision: 0.7405\n",
            "Weighted Average Recall: 0.7041\n",
            "Weighted Average F1-Score: 0.6512\n",
            "\n",
            "--- Model Confidence & Calibration Metrics ---\n",
            "Average Prediction Confidence: 0.8593\n",
            "Confidence Standard Deviation: 0.1771\n",
            "Average Prediction Entropy: 0.4163\n",
            "Expected Calibration Error: 0.1552\n",
            "\n",
            "Final Test Loss: 0.8830\n",
            "===============================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "CONFIG = {\n",
        "    \"batch_size\": 128,\n",
        "    \"num_epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"split_seed\": 42,\n",
        "    \"train_split\": 0.70,\n",
        "    \"val_split\": 0.15,\n",
        "    \"test_split\": 0.15,\n",
        "    \"num_classes\": 10,  # Fashion-MNIST has 10 classes\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"checkpoint_path\": \"./best_model.pth\",\n",
        "}\n",
        "\n",
        "# --- Transformer Configuration ---\n",
        "TRANSFORMER_CONFIG = {\n",
        "    \"embedding_dim\": 32,\n",
        "    \"nhead\": 16,\n",
        "    \"num_encoder_layers\": 3,\n",
        "    \"dim_feedforward\": 2,\n",
        "    \"dropout\": 0.1,\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# Callback Classes\n",
        "# ==========================================\n",
        "\n",
        "class Callback:\n",
        "    \"\"\"Base callback class\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_training_end(self):\n",
        "        pass\n",
        "\n",
        "class ReduceLROnPlateau(Callback):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving\"\"\"\n",
        "    def __init__(self, optimizer, monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7, verbose=1):\n",
        "        self.optimizer = optimizer\n",
        "        self.monitor = monitor\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                old_lr = self.optimizer.param_groups[0]['lr']\n",
        "                new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "                if new_lr != old_lr:\n",
        "                    self.optimizer.param_groups[0]['lr'] = new_lr\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nReducing learning rate from {old_lr:.2e} to {new_lr:.2e}\")\n",
        "                    self.wait = 0\n",
        "\n",
        "class EarlyStopping(Callback):\n",
        "    \"\"\"Stop training when a monitored metric has stopped improving\"\"\"\n",
        "    def __init__(self, monitor='val_loss', patience=7, restore_best_weights=True, verbose=1):\n",
        "        self.monitor = monitor\n",
        "        self.patience = patience\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.best_weights = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None:\n",
        "            return False\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return False\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def on_training_end(self, model=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose:\n",
        "            print(f\"Restored model weights from the end of the best epoch: {self.stopped_epoch + 1 - self.patience}\")\n",
        "        if model is not None and self.restore_best_weights and self.best_weights is not None:\n",
        "            model.load_state_dict(self.best_weights)\n",
        "\n",
        "class ModelCheckpoint(Callback):\n",
        "    \"\"\"Save the model after every epoch\"\"\"\n",
        "    def __init__(self, filepath, save_best_only=True, monitor='val_accuracy', verbose=1):\n",
        "        self.filepath = filepath\n",
        "        self.save_best_only = save_best_only\n",
        "        self.monitor = monitor\n",
        "        self.verbose = verbose\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None or model is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if not self.save_best_only:\n",
        "            filepath = self.filepath.replace('.pth', f'_epoch_{epoch + 1}.pth')\n",
        "            torch.save(model.state_dict(), filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "\n",
        "# ==========================================\n",
        "# Data Preprocessing\n",
        "# ==========================================\n",
        "\n",
        "def get_dataloaders(config):\n",
        "    \"\"\"Downloads, prepares, and splits Fashion-MNIST data, returning DataLoaders.\"\"\"\n",
        "\n",
        "    # Data augmentation for training\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=10),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.2860], std=[0.3530]),  # Fashion-MNIST specific normalization\n",
        "    ])\n",
        "\n",
        "    # No augmentation for validation/test\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.2860], std=[0.3530]),  # Fashion-MNIST specific normalization\n",
        "    ])\n",
        "\n",
        "    # Download Fashion-MNIST dataset\n",
        "    print(\"Downloading Fashion-MNIST dataset...\")\n",
        "    train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    test_dataset_original = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=test_transform\n",
        "    )\n",
        "\n",
        "    # Combine train and test datasets for custom splitting\n",
        "    # We need to apply the same transform to the combined dataset for consistency\n",
        "    combined_train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=False,\n",
        "        transform=test_transform  # Use test transform for consistent splitting\n",
        "    )\n",
        "\n",
        "    full_dataset = torch.utils.data.ConcatDataset([combined_train_dataset, test_dataset_original])\n",
        "\n",
        "    # Ensure reproducible splits\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(config[\"train_split\"] * total_size)\n",
        "    val_size = int(config[\"val_split\"] * total_size)\n",
        "    test_size = int(config[\"test_split\"] * total_size)\n",
        "\n",
        "    # Adjust sizes to ensure they sum to total_size (handle rounding issues)\n",
        "    actual_total = train_size + val_size + test_size\n",
        "    if actual_total != total_size:\n",
        "        # Add/subtract the difference to test_size\n",
        "        test_size += (total_size - actual_total)\n",
        "\n",
        "    print(f\"Dataset splits - Train: {train_size}, Val: {val_size}, Test: {test_size}, Total: {total_size}\")\n",
        "\n",
        "    # Create reproducible generator for splitting\n",
        "    generator = torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    train_subset, val_subset, test_subset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size], generator=generator\n",
        "    )\n",
        "\n",
        "    # Create a custom dataset class to apply different transforms to train subset\n",
        "    class TransformSubset(Dataset):\n",
        "        def __init__(self, subset, transform=None):\n",
        "            self.subset = subset\n",
        "            self.transform = transform\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            x, y = self.subset[index]\n",
        "            if self.transform:\n",
        "                # Convert tensor back to PIL Image for transforms\n",
        "                if isinstance(x, torch.Tensor):\n",
        "                    x = transforms.ToPILImage()(x)\n",
        "                x = self.transform(x)\n",
        "            return x, y\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.subset)\n",
        "\n",
        "    # Apply training transforms to training subset\n",
        "    train_subset_with_augment = TransformSubset(train_subset, train_transform)\n",
        "\n",
        "    # Set worker init function for reproducible DataLoader behavior\n",
        "    def worker_init_fn(worker_id):\n",
        "        np.random.seed(config[\"split_seed\"] + worker_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset_with_augment,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# ==========================================\n",
        "# Model Architecture and Training\n",
        "# ==========================================\n",
        "\n",
        "class NonResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    This block is a standard convolutional block WITHOUT the residual connection.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(NonResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNetTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    A hybrid architecture combining a non-residual CNN backbone with a Transformer encoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, block, layers, num_classes, t_config):\n",
        "        super(ResNetTransformer, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.embedding_dim = t_config[\"embedding_dim\"]\n",
        "\n",
        "        # 1. CNN Backbone (Feature Extractor)\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        # 2. Projection heads to create tokens from feature maps\n",
        "        self.projections = nn.ModuleList([\n",
        "            self._create_projection(64, self.embedding_dim),   # From initial maxpool\n",
        "            self._create_projection(64, self.embedding_dim),   # From layer1\n",
        "            self._create_projection(128, self.embedding_dim),  # From layer2\n",
        "            self._create_projection(256, self.embedding_dim),  # From layer3\n",
        "            self._create_projection(512, self.embedding_dim)   # From layer4\n",
        "        ])\n",
        "\n",
        "        # 3. Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=self.embedding_dim,\n",
        "            nhead=t_config[\"nhead\"],\n",
        "            dim_feedforward=t_config[\"dim_feedforward\"],\n",
        "            dropout=t_config[\"dropout\"],\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=t_config[\"num_encoder_layers\"]\n",
        "        )\n",
        "\n",
        "        # 4. Final Classifier\n",
        "        self.classifier = nn.Linear(self.embedding_dim, num_classes)\n",
        "\n",
        "    def _create_projection(self, in_features, out_features):\n",
        "        return nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, out_features)\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        current_in_channels = self.in_channels\n",
        "        for s in strides:\n",
        "            layers.append(block(current_in_channels, out_channels, s))\n",
        "            current_in_channels = out_channels\n",
        "        self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Pass through CNN backbone and capture features\n",
        "        features = []\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        features.append(x)\n",
        "\n",
        "        x = self.layer1(x); features.append(x)\n",
        "        x = self.layer2(x); features.append(x)\n",
        "        x = self.layer3(x); features.append(x)\n",
        "        x = self.layer4(x); features.append(x)\n",
        "\n",
        "        # 2. Project features to tokens\n",
        "        tokens = []\n",
        "        for i, feature_map in enumerate(features):\n",
        "            tokens.append(self.projections[i](feature_map))\n",
        "\n",
        "        # 3. Stack tokens and pass through Transformer\n",
        "        token_sequence = torch.stack(tokens, dim=1)\n",
        "        transformer_out = self.transformer_encoder(token_sequence)\n",
        "\n",
        "        # 4. Aggregate and classify\n",
        "        aggregated_vector = transformer_out.mean(dim=1)\n",
        "        logits = self.classifier(aggregated_vector)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def ResNetTransformer18(num_classes=200, t_config=TRANSFORMER_CONFIG):\n",
        "    return ResNetTransformer(NonResidualBlock, [2, 2, 2, 2], num_classes, t_config)\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, config):\n",
        "    \"\"\"Main training loop with callbacks.\"\"\"\n",
        "    device = config[\"device\"]\n",
        "    model.to(device)\n",
        "\n",
        "    # Set seeds for reproducible training\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(config[\"split_seed\"])\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "    # Initialize callbacks\n",
        "    callbacks = [\n",
        "        ReduceLROnPlateau(\n",
        "            optimizer=optimizer,\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=7,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=config[\"checkpoint_path\"],\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        running_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\", leave=False)\n",
        "        for images, labels in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_loss / train_total\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['num_epochs']} | Time: {time.time() - start_time:.2f}s | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Prepare logs for callbacks\n",
        "        logs = {\n",
        "            'train_loss': train_loss,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc\n",
        "        }\n",
        "\n",
        "        # Execute callbacks\n",
        "        for callback in callbacks:\n",
        "            if isinstance(callback, EarlyStopping):\n",
        "                if callback.on_epoch_end(epoch, logs, model):\n",
        "                    early_stop = True\n",
        "                    break\n",
        "            elif isinstance(callback, ModelCheckpoint):\n",
        "                callback.on_epoch_end(epoch, logs, model)\n",
        "            else:\n",
        "                callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    # Execute callback cleanup\n",
        "    for callback in callbacks:\n",
        "        if isinstance(callback, EarlyStopping):\n",
        "            callback.on_training_end(model)\n",
        "        else:\n",
        "            callback.on_training_end()\n",
        "\n",
        "    print(\"--- Training Finished ---\\n\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "\n",
        "def calculate_top_k_accuracy(outputs, labels, k_values=[1, 3, 5]):\n",
        "    \"\"\"Calculate top-k accuracy for given k values.\"\"\"\n",
        "    batch_size = labels.size(0)\n",
        "    _, pred = outputs.topk(max(k_values), 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "    top_k_accuracies = {}\n",
        "    for k in k_values:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        top_k_accuracies[k] = correct_k.item() / batch_size\n",
        "\n",
        "    return top_k_accuracies\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "    \"\"\"Calculate entropy of probability distributions.\"\"\"\n",
        "    # Add small epsilon to avoid log(0)\n",
        "    epsilon = 1e-8\n",
        "    probs = probs + epsilon\n",
        "    entropy = -torch.sum(probs * torch.log(probs), dim=1)\n",
        "    return entropy\n",
        "\n",
        "def calculate_ece(confidences, accuracies, n_bins=10):\n",
        "    \"\"\"Calculate Expected Calibration Error.\"\"\"\n",
        "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers = bin_boundaries[:-1]\n",
        "    bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    ece = 0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower.item()) & (confidences <= bin_upper.item())\n",
        "        prop_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prop_in_bin.item() > 0:\n",
        "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece.item()\n",
        "\n",
        "def comprehensive_evaluation(model, test_loader, criterion, device):\n",
        "    \"\"\"Comprehensive evaluation with all requested metrics.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_confidences = []\n",
        "    all_entropies = []\n",
        "    all_top_k_results = {1: [], 3: [], 5: []}\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Convert outputs to probabilities\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Get predictions and confidences\n",
        "            confidences, predictions = torch.max(probs, dim=1)\n",
        "\n",
        "            # Calculate entropy\n",
        "            entropies = calculate_entropy(probs)\n",
        "\n",
        "            # Calculate top-k accuracies\n",
        "            top_k_accs = calculate_top_k_accuracy(outputs, labels, [1, 3, 5])\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_entropies.extend(entropies.cpu().numpy())\n",
        "\n",
        "            for k in [1, 3, 5]:\n",
        "                all_top_k_results[k].extend([top_k_accs[k]] * labels.size(0))\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_confidences = np.array(all_confidences)\n",
        "    all_entropies = np.array(all_entropies)\n",
        "\n",
        "    # Calculate basic metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    # Calculate top-k accuracies\n",
        "    top1 = np.mean([pred == label for pred, label in zip(all_predictions, all_labels)])\n",
        "    top3 = np.mean(all_top_k_results[3])\n",
        "    top5 = np.mean(all_top_k_results[5])\n",
        "\n",
        "    # Calculate precision, recall, f1-score\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate confidence and calibration metrics\n",
        "    avg_confidence = np.mean(all_confidences)\n",
        "    std_confidence = np.std(all_confidences)\n",
        "    avg_entropy = np.mean(all_entropies)\n",
        "\n",
        "    # Calculate ECE\n",
        "    accuracies = (all_predictions == all_labels).astype(float)\n",
        "    ece = calculate_ece(torch.tensor(all_confidences), torch.tensor(accuracies))\n",
        "\n",
        "    return {\n",
        "        'test_loss': avg_loss,\n",
        "        'top1': top1,\n",
        "        'top3': top3,\n",
        "        'top5': top5,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_weighted': precision_weighted,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'std_confidence': std_confidence,\n",
        "        'avg_entropy': avg_entropy,\n",
        "        'ece': ece\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# Main Execution\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set global seeds for full reproducibility\n",
        "    torch.manual_seed(CONFIG[\"split_seed\"])\n",
        "    np.random.seed(CONFIG[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(CONFIG[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(CONFIG[\"split_seed\"])\n",
        "        # Ensure deterministic behavior on CUDA\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"Using device: {CONFIG['device']}\")\n",
        "    print(f\"Reproducibility seed: {CONFIG['split_seed']}\")\n",
        "\n",
        "    # Get data loaders\n",
        "    dataloaders = get_dataloaders(CONFIG)\n",
        "    if dataloaders is None:\n",
        "        print(\"Could not prepare data. Halting execution.\", file=sys.stderr)\n",
        "        sys.exit(1)  # Exit if data preparation failed\n",
        "\n",
        "    train_loader, val_loader, test_loader = dataloaders\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = ResNetTransformer18(num_classes=CONFIG[\"num_classes\"], t_config=TRANSFORMER_CONFIG)\n",
        "    trained_model = train_and_validate(model, train_loader, val_loader, CONFIG)\n",
        "\n",
        "    # Comprehensive evaluation on the test set\n",
        "    print(\"--- Starting Comprehensive Evaluation on Test Set ---\")\n",
        "    results = comprehensive_evaluation(trained_model, test_loader, nn.CrossEntropyLoss(), CONFIG[\"device\"])\n",
        "\n",
        "    # Print all requested metrics\n",
        "    print(\"\\n--- Top-K Accuracy Results ---\")\n",
        "    print(f\"Top-1 Accuracy: {results['top1'] * 100:.2f}%\")\n",
        "    print(f\"Top-3 Accuracy: {results['top3'] * 100:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {results['top5'] * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Additional Performance Metrics ---\")\n",
        "    print(f\"Macro Average Precision: {results['precision_macro']:.4f}\")\n",
        "    print(f\"Macro Average Recall: {results['recall_macro']:.4f}\")\n",
        "    print(f\"Macro Average F1-Score: {results['f1_macro']:.4f}\")\n",
        "    print(f\"Weighted Average Precision: {results['precision_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average Recall: {results['recall_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average F1-Score: {results['f1_weighted']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Model Confidence & Calibration Metrics ---\")\n",
        "    print(f\"Average Prediction Confidence: {results['avg_confidence']:.4f}\")\n",
        "    print(f\"Confidence Standard Deviation: {results['std_confidence']:.4f}\")\n",
        "    print(f\"Average Prediction Entropy: {results['avg_entropy']:.4f}\")\n",
        "    print(f\"Expected Calibration Error: {results['ece']:.4f}\")\n",
        "\n",
        "    print(f\"\\nFinal Test Loss: {results['test_loss']:.4f}\")\n",
        "    print(\"===============================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sco7zqfcOE6"
      },
      "source": [
        "## Hybrid Transformer on ResNet-18 (Learnable PE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35H-PINZcUxw",
        "outputId": "0932ce47-34c0-48c6-90e8-1f98f5eeebdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Reproducibility seed: 42\n",
            "Downloading Fashion-MNIST dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.8MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 204kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.79MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 9.67MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splits - Train: 49000, Val: 10500, Test: 10500, Total: 70000\n",
            "Model has 12845002 parameters\n",
            "Trainable parameters: 12845002\n",
            "\n",
            "--- Starting Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Time: 45.99s | Train Loss: 1.1202, Train Acc: 53.83% | Val Loss: 0.9256, Val Acc: 66.02%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 | Time: 43.91s | Train Loss: 0.8090, Train Acc: 68.80% | Val Loss: 1.0781, Val Acc: 61.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100 | Time: 43.64s | Train Loss: 0.6771, Train Acc: 74.65% | Val Loss: 0.7664, Val Acc: 71.12%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 | Time: 42.80s | Train Loss: 0.6153, Train Acc: 77.06% | Val Loss: 0.7020, Val Acc: 75.95%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100 | Time: 43.91s | Train Loss: 0.5787, Train Acc: 78.36% | Val Loss: 0.7071, Val Acc: 74.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 | Time: 43.31s | Train Loss: 0.5436, Train Acc: 79.63% | Val Loss: 0.8867, Val Acc: 73.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100 | Time: 43.63s | Train Loss: 0.5178, Train Acc: 80.56% | Val Loss: 0.7415, Val Acc: 74.01%\n",
            "\n",
            "Reducing learning rate from 1.00e-03 to 2.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 | Time: 44.21s | Train Loss: 0.4405, Train Acc: 83.53% | Val Loss: 0.7262, Val Acc: 75.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 | Time: 43.52s | Train Loss: 0.4226, Train Acc: 84.21% | Val Loss: 0.7196, Val Acc: 75.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 | Time: 43.17s | Train Loss: 0.4148, Train Acc: 84.42% | Val Loss: 0.7295, Val Acc: 75.52%\n",
            "\n",
            "Reducing learning rate from 2.00e-04 to 4.00e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 | Time: 43.58s | Train Loss: 0.3962, Train Acc: 85.13% | Val Loss: 0.7143, Val Acc: 76.16%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 | Time: 43.29s | Train Loss: 0.3918, Train Acc: 85.28% | Val Loss: 0.7218, Val Acc: 75.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100 | Time: 43.12s | Train Loss: 0.3877, Train Acc: 85.44% | Val Loss: 0.7466, Val Acc: 75.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100 | Time: 43.27s | Train Loss: 0.3854, Train Acc: 85.59% | Val Loss: 0.7243, Val Acc: 75.94%\n",
            "\n",
            "Reducing learning rate from 4.00e-05 to 8.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100 | Time: 43.68s | Train Loss: 0.3779, Train Acc: 85.77% | Val Loss: 0.7629, Val Acc: 74.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100 | Time: 42.86s | Train Loss: 0.3767, Train Acc: 85.91% | Val Loss: 0.7598, Val Acc: 75.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100 | Time: 43.11s | Train Loss: 0.3782, Train Acc: 85.66% | Val Loss: 0.7516, Val Acc: 75.20%\n",
            "\n",
            "Reducing learning rate from 8.00e-06 to 1.60e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100 | Time: 44.41s | Train Loss: 0.3769, Train Acc: 85.83% | Val Loss: 0.7488, Val Acc: 75.18%\n",
            "\n",
            "Early stopping at epoch 18\n",
            "Restored model weights from the end of the best epoch: 11\n",
            "--- Training Finished ---\n",
            "\n",
            "--- Starting Comprehensive Evaluation on Test Set ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 83/83 [00:02<00:00, 29.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Top-K Accuracy Results ---\n",
            "Top-1 Accuracy: 75.18%\n",
            "Top-3 Accuracy: 96.93%\n",
            "Top-5 Accuracy: 99.30%\n",
            "\n",
            "--- Additional Performance Metrics ---\n",
            "Macro Average Precision: 0.7596\n",
            "Macro Average Recall: 0.7480\n",
            "Macro Average F1-Score: 0.7207\n",
            "Weighted Average Precision: 0.7589\n",
            "Weighted Average Recall: 0.7518\n",
            "Weighted Average F1-Score: 0.7231\n",
            "\n",
            "--- Model Confidence & Calibration Metrics ---\n",
            "Average Prediction Confidence: 0.8728\n",
            "Confidence Standard Deviation: 0.1707\n",
            "Average Prediction Entropy: 0.3645\n",
            "Expected Calibration Error: 0.1210\n",
            "\n",
            "Final Test Loss: 0.7471\n",
            "===============================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "CONFIG = {\n",
        "    \"batch_size\": 128,\n",
        "    \"num_epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"split_seed\": 42,\n",
        "    \"train_split\": 0.70,\n",
        "    \"val_split\": 0.15,\n",
        "    \"test_split\": 0.15,\n",
        "    \"num_classes\": 10,  # Fashion-MNIST has 10 classes\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"checkpoint_path\": \"./best_model.pth\",\n",
        "}\n",
        "\n",
        "# --- Transformer Configuration ---\n",
        "TRANSFORMER_CONFIG = {\n",
        "    \"embedding_dim\": 256,       # Dimension of the tokens fed to the transformer\n",
        "    \"nhead\": 8,                 # Number of attention heads\n",
        "    \"num_encoder_layers\": 3,    # Number of transformer encoder layers\n",
        "    \"dim_feedforward\": 512,     # Hidden dimension in the feed-forward network\n",
        "    \"dropout\": 0.1,\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# Callback Classes\n",
        "# ==========================================\n",
        "\n",
        "class Callback:\n",
        "    \"\"\"Base callback class\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_training_end(self):\n",
        "        pass\n",
        "\n",
        "class ReduceLROnPlateau(Callback):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving\"\"\"\n",
        "    def __init__(self, optimizer, monitor='val_accuracy', factor=0.2, patience=3, min_lr=1e-7, verbose=1):\n",
        "        self.optimizer = optimizer\n",
        "        self.monitor = monitor\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                old_lr = self.optimizer.param_groups[0]['lr']\n",
        "                new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "                if new_lr != old_lr:\n",
        "                    self.optimizer.param_groups[0]['lr'] = new_lr\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nReducing learning rate from {old_lr:.2e} to {new_lr:.2e}\")\n",
        "                    self.wait = 0\n",
        "\n",
        "class EarlyStopping(Callback):\n",
        "    \"\"\"Stop training when a monitored metric has stopped improving\"\"\"\n",
        "    def __init__(self, monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1):\n",
        "        self.monitor = monitor\n",
        "        self.patience = patience\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.best_weights = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None:\n",
        "            return False\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return False\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def on_training_end(self, model=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose:\n",
        "            print(f\"Restored model weights from the end of the best epoch: {self.stopped_epoch + 1 - self.patience}\")\n",
        "        if model is not None and self.restore_best_weights and self.best_weights is not None:\n",
        "            model.load_state_dict(self.best_weights)\n",
        "\n",
        "class ModelCheckpoint(Callback):\n",
        "    \"\"\"Save the model after every epoch\"\"\"\n",
        "    def __init__(self, filepath, save_best_only=True, monitor='val_accuracy', verbose=1):\n",
        "        self.filepath = filepath\n",
        "        self.save_best_only = save_best_only\n",
        "        self.monitor = monitor\n",
        "        self.verbose = verbose\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None or model is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if not self.save_best_only:\n",
        "            filepath = self.filepath.replace('.pth', f'_epoch_{epoch + 1}.pth')\n",
        "            torch.save(model.state_dict(), filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "\n",
        "# ==========================================\n",
        "# Data Preprocessing\n",
        "# ==========================================\n",
        "\n",
        "def get_dataloaders(config):\n",
        "    \"\"\"Downloads, prepares, and splits Fashion-MNIST data, returning DataLoaders.\"\"\"\n",
        "\n",
        "    # Data augmentation for training\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=10),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.2860], std=[0.3530]),  # Fashion-MNIST specific normalization\n",
        "    ])\n",
        "\n",
        "    # No augmentation for validation/test\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.2860], std=[0.3530]),  # Fashion-MNIST specific normalization\n",
        "    ])\n",
        "\n",
        "    # Download Fashion-MNIST dataset\n",
        "    print(\"Downloading Fashion-MNIST dataset...\")\n",
        "    train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    test_dataset_original = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=test_transform\n",
        "    )\n",
        "\n",
        "    # Combine train and test datasets for custom splitting\n",
        "    # We need to apply the same transform to the combined dataset for consistency\n",
        "    combined_train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=False,\n",
        "        transform=test_transform  # Use test transform for consistent splitting\n",
        "    )\n",
        "\n",
        "    full_dataset = torch.utils.data.ConcatDataset([combined_train_dataset, test_dataset_original])\n",
        "\n",
        "    # Ensure reproducible splits\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(config[\"train_split\"] * total_size)\n",
        "    val_size = int(config[\"val_split\"] * total_size)\n",
        "    test_size = int(config[\"test_split\"] * total_size)\n",
        "\n",
        "    # Adjust sizes to ensure they sum to total_size (handle rounding issues)\n",
        "    actual_total = train_size + val_size + test_size\n",
        "    if actual_total != total_size:\n",
        "        # Add/subtract the difference to test_size\n",
        "        test_size += (total_size - actual_total)\n",
        "\n",
        "    print(f\"Dataset splits - Train: {train_size}, Val: {val_size}, Test: {test_size}, Total: {total_size}\")\n",
        "\n",
        "    # Create reproducible generator for splitting\n",
        "    generator = torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    train_subset, val_subset, test_subset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size], generator=generator\n",
        "    )\n",
        "\n",
        "    # Create a custom dataset class to apply different transforms to train subset\n",
        "    class TransformSubset(Dataset):\n",
        "        def __init__(self, subset, transform=None):\n",
        "            self.subset = subset\n",
        "            self.transform = transform\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            x, y = self.subset[index]\n",
        "            if self.transform:\n",
        "                # Convert tensor back to PIL Image for transforms\n",
        "                if isinstance(x, torch.Tensor):\n",
        "                    x = transforms.ToPILImage()(x)\n",
        "                x = self.transform(x)\n",
        "            return x, y\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.subset)\n",
        "\n",
        "    # Apply training transforms to training subset\n",
        "    train_subset_with_augment = TransformSubset(train_subset, train_transform)\n",
        "\n",
        "    # Set worker init function for reproducible DataLoader behavior\n",
        "    def worker_init_fn(worker_id):\n",
        "        np.random.seed(config[\"split_seed\"] + worker_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset_with_augment,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# ==========================================\n",
        "# Model Architecture and Training\n",
        "# ==========================================\n",
        "\n",
        "class NonResidualBlock(nn.Module):\n",
        "    \"\"\"A standard convolutional block WITHOUT the residual connection.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(NonResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNetTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    A hybrid architecture combining a non-residual CNN backbone with a Transformer encoder,\n",
        "    including positional embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, block, layers, num_classes, t_config):\n",
        "        super(ResNetTransformer, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.embedding_dim = t_config[\"embedding_dim\"]\n",
        "        self.num_tokens = len(layers) + 1  # 4 layers + 1 initial capture\n",
        "\n",
        "        # 1. CNN Backbone (Feature Extractor)\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        # 2. Projection heads to create tokens from feature maps\n",
        "        self.projections = nn.ModuleList([\n",
        "            self._create_projection(64, self.embedding_dim),\n",
        "            self._create_projection(64, self.embedding_dim),\n",
        "            self._create_projection(128, self.embedding_dim),\n",
        "            self._create_projection(256, self.embedding_dim),\n",
        "            self._create_projection(512, self.embedding_dim)\n",
        "        ])\n",
        "\n",
        "        # 3. Learnable Positional Embedding\n",
        "        self.positional_embedding = nn.Parameter(torch.randn(1, self.num_tokens, self.embedding_dim))\n",
        "\n",
        "        # 4. Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=self.embedding_dim,\n",
        "            nhead=t_config[\"nhead\"],\n",
        "            dim_feedforward=t_config[\"dim_feedforward\"],\n",
        "            dropout=t_config[\"dropout\"],\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=t_config[\"num_encoder_layers\"]\n",
        "        )\n",
        "\n",
        "        # 5. Final Classifier\n",
        "        self.classifier = nn.Linear(self.embedding_dim, num_classes)\n",
        "\n",
        "    def _create_projection(self, in_features, out_features):\n",
        "        return nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, out_features)\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        current_in_channels = self.in_channels\n",
        "        for s in strides:\n",
        "            layers.append(block(current_in_channels, out_channels, s))\n",
        "            current_in_channels = out_channels\n",
        "        self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Pass through CNN backbone and capture features\n",
        "        features = []\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        features.append(x)  # Capture 1: After initial maxpool\n",
        "\n",
        "        x = self.layer1(x); features.append(x)  # Capture 2: After layer1\n",
        "        x = self.layer2(x); features.append(x)  # Capture 3: After layer2\n",
        "        x = self.layer3(x); features.append(x)  # Capture 4: After layer3\n",
        "        x = self.layer4(x); features.append(x)  # Capture 5: After layer4\n",
        "\n",
        "        # 2. Project features to tokens\n",
        "        tokens = [self.projections[i](feature_map) for i, feature_map in enumerate(features)]\n",
        "\n",
        "        # 3. Stack tokens into a sequence\n",
        "        token_sequence = torch.stack(tokens, dim=1)\n",
        "\n",
        "        # 4. Add positional embedding\n",
        "        token_sequence += self.positional_embedding\n",
        "\n",
        "        # 5. Pass through Transformer\n",
        "        transformer_out = self.transformer_encoder(token_sequence)\n",
        "\n",
        "        # 6. Aggregate and classify\n",
        "        aggregated_vector = transformer_out.mean(dim=1)\n",
        "        logits = self.classifier(aggregated_vector)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, config):\n",
        "    \"\"\"Main training loop with callbacks.\"\"\"\n",
        "    device = config[\"device\"]\n",
        "    model.to(device)\n",
        "\n",
        "    # Set seeds for reproducible training\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(config[\"split_seed\"])\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "    # Initialize callbacks\n",
        "    callbacks = [\n",
        "        ReduceLROnPlateau(\n",
        "            optimizer=optimizer,\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=7,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=config[\"checkpoint_path\"],\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        running_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\", leave=False)\n",
        "        for images, labels in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_loss / train_total\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['num_epochs']} | Time: {time.time() - start_time:.2f}s | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Prepare logs for callbacks\n",
        "        logs = {\n",
        "            'train_loss': train_loss,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc\n",
        "        }\n",
        "\n",
        "        # Execute callbacks\n",
        "        for callback in callbacks:\n",
        "            if isinstance(callback, EarlyStopping):\n",
        "                if callback.on_epoch_end(epoch, logs, model):\n",
        "                    early_stop = True\n",
        "                    break\n",
        "            elif isinstance(callback, ModelCheckpoint):\n",
        "                callback.on_epoch_end(epoch, logs, model)\n",
        "            else:\n",
        "                callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    # Execute callback cleanup\n",
        "    for callback in callbacks:\n",
        "        if isinstance(callback, EarlyStopping):\n",
        "            callback.on_training_end(model)\n",
        "        else:\n",
        "            callback.on_training_end()\n",
        "\n",
        "    print(\"--- Training Finished ---\\n\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "\n",
        "def calculate_top_k_accuracy(outputs, labels, k_values=[1, 3, 5]):\n",
        "    \"\"\"Calculate top-k accuracy for given k values.\"\"\"\n",
        "    batch_size = labels.size(0)\n",
        "    _, pred = outputs.topk(max(k_values), 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "    top_k_accuracies = {}\n",
        "    for k in k_values:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        top_k_accuracies[k] = correct_k.item() / batch_size\n",
        "\n",
        "    return top_k_accuracies\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "    \"\"\"Calculate entropy of probability distributions.\"\"\"\n",
        "    # Add small epsilon to avoid log(0)\n",
        "    epsilon = 1e-8\n",
        "    probs = probs + epsilon\n",
        "    entropy = -torch.sum(probs * torch.log(probs), dim=1)\n",
        "    return entropy\n",
        "\n",
        "def calculate_ece(confidences, accuracies, n_bins=10):\n",
        "    \"\"\"Calculate Expected Calibration Error.\"\"\"\n",
        "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers = bin_boundaries[:-1]\n",
        "    bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    ece = 0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower.item()) & (confidences <= bin_upper.item())\n",
        "        prop_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prop_in_bin.item() > 0:\n",
        "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece.item()\n",
        "\n",
        "def comprehensive_evaluation(model, test_loader, criterion, device):\n",
        "    \"\"\"Comprehensive evaluation with all requested metrics.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_confidences = []\n",
        "    all_entropies = []\n",
        "    all_top_k_results = {1: [], 3: [], 5: []}\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Convert outputs to probabilities\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Get predictions and confidences\n",
        "            confidences, predictions = torch.max(probs, dim=1)\n",
        "\n",
        "            # Calculate entropy\n",
        "            entropies = calculate_entropy(probs)\n",
        "\n",
        "            # Calculate top-k accuracies\n",
        "            top_k_accs = calculate_top_k_accuracy(outputs, labels, [1, 3, 5])\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_entropies.extend(entropies.cpu().numpy())\n",
        "\n",
        "            for k in [1, 3, 5]:\n",
        "                all_top_k_results[k].extend([top_k_accs[k]] * labels.size(0))\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_confidences = np.array(all_confidences)\n",
        "    all_entropies = np.array(all_entropies)\n",
        "\n",
        "    # Calculate basic metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    # Calculate top-k accuracies\n",
        "    top1 = np.mean([pred == label for pred, label in zip(all_predictions, all_labels)])\n",
        "    top3 = np.mean(all_top_k_results[3])\n",
        "    top5 = np.mean(all_top_k_results[5])\n",
        "\n",
        "    # Calculate precision, recall, f1-score\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate confidence and calibration metrics\n",
        "    avg_confidence = np.mean(all_confidences)\n",
        "    std_confidence = np.std(all_confidences)\n",
        "    avg_entropy = np.mean(all_entropies)\n",
        "\n",
        "    # Calculate ECE\n",
        "    accuracies = (all_predictions == all_labels).astype(float)\n",
        "    ece = calculate_ece(torch.tensor(all_confidences), torch.tensor(accuracies))\n",
        "\n",
        "    return {\n",
        "        'test_loss': avg_loss,\n",
        "        'top1': top1,\n",
        "        'top3': top3,\n",
        "        'top5': top5,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_weighted': precision_weighted,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'std_confidence': std_confidence,\n",
        "        'avg_entropy': avg_entropy,\n",
        "        'ece': ece\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# Main Execution\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set global seeds for full reproducibility\n",
        "    torch.manual_seed(CONFIG[\"split_seed\"])\n",
        "    np.random.seed(CONFIG[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(CONFIG[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(CONFIG[\"split_seed\"])\n",
        "        # Ensure deterministic behavior on CUDA\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"Using device: {CONFIG['device']}\")\n",
        "    print(f\"Reproducibility seed: {CONFIG['split_seed']}\")\n",
        "\n",
        "    # Get data loaders\n",
        "    dataloaders = get_dataloaders(CONFIG)\n",
        "    if dataloaders is None:\n",
        "        print(\"Could not prepare data. Halting execution.\", file=sys.stderr)\n",
        "        sys.exit(1)  # Exit if data preparation failed\n",
        "\n",
        "    train_loader, val_loader, test_loader = dataloaders\n",
        "\n",
        "    # Initialize and train model with ResNetTransformer\n",
        "    model = ResNetTransformer(\n",
        "        block=NonResidualBlock,\n",
        "        layers=[2, 2, 2, 2],\n",
        "        num_classes=CONFIG[\"num_classes\"],\n",
        "        t_config=TRANSFORMER_CONFIG\n",
        "    )\n",
        "\n",
        "    print(f\"Model has {sum(p.numel() for p in model.parameters())} parameters\")\n",
        "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "    trained_model = train_and_validate(model, train_loader, val_loader, CONFIG)\n",
        "\n",
        "    # Comprehensive evaluation on the test set\n",
        "    print(\"--- Starting Comprehensive Evaluation on Test Set ---\")\n",
        "    results = comprehensive_evaluation(trained_model, test_loader, nn.CrossEntropyLoss(), CONFIG[\"device\"])\n",
        "\n",
        "    # Print all requested metrics\n",
        "    print(\"\\n--- Top-K Accuracy Results ---\")\n",
        "    print(f\"Top-1 Accuracy: {results['top1'] * 100:.2f}%\")\n",
        "    print(f\"Top-3 Accuracy: {results['top3'] * 100:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {results['top5'] * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Additional Performance Metrics ---\")\n",
        "    print(f\"Macro Average Precision: {results['precision_macro']:.4f}\")\n",
        "    print(f\"Macro Average Recall: {results['recall_macro']:.4f}\")\n",
        "    print(f\"Macro Average F1-Score: {results['f1_macro']:.4f}\")\n",
        "    print(f\"Weighted Average Precision: {results['precision_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average Recall: {results['recall_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average F1-Score: {results['f1_weighted']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Model Confidence & Calibration Metrics ---\")\n",
        "    print(f\"Average Prediction Confidence: {results['avg_confidence']:.4f}\")\n",
        "    print(f\"Confidence Standard Deviation: {results['std_confidence']:.4f}\")\n",
        "    print(f\"Average Prediction Entropy: {results['avg_entropy']:.4f}\")\n",
        "    print(f\"Expected Calibration Error: {results['ece']:.4f}\")\n",
        "\n",
        "    print(f\"\\nFinal Test Loss: {results['test_loss']:.4f}\")\n",
        "    print(\"===============================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY7hR3CScRKx"
      },
      "source": [
        "## Hybrid Transformer on ResNet-18 (RoPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_WZ5oNzcUE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75baf062-c8f9-46d1-9d9b-a229f7375729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Reproducibility seed: 42\n",
            "Downloading Fashion-MNIST dataset...\n",
            "Dataset splits - Train: 49000, Val: 10500, Test: 10500, Total: 70000\n",
            "\n",
            "--- Starting Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Time: 43.91s | Train Loss: 0.9912, Train Acc: 60.80% | Val Loss: 0.9640, Val Acc: 66.66%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 | Time: 45.46s | Train Loss: 0.7044, Train Acc: 72.82% | Val Loss: 1.2787, Val Acc: 57.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100 | Time: 44.05s | Train Loss: 0.6216, Train Acc: 76.42% | Val Loss: 0.8191, Val Acc: 70.75%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 | Time: 45.18s | Train Loss: 0.5766, Train Acc: 77.94% | Val Loss: 0.9065, Val Acc: 68.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100 | Time: 44.11s | Train Loss: 0.5464, Train Acc: 79.28% | Val Loss: 1.2293, Val Acc: 62.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 | Time: 44.52s | Train Loss: 0.5174, Train Acc: 80.51% | Val Loss: 0.9649, Val Acc: 70.82%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100 | Time: 44.54s | Train Loss: 0.4978, Train Acc: 81.26% | Val Loss: 1.4199, Val Acc: 57.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 | Time: 44.43s | Train Loss: 0.4853, Train Acc: 81.86% | Val Loss: 1.1152, Val Acc: 63.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 | Time: 45.09s | Train Loss: 0.4718, Train Acc: 82.23% | Val Loss: 0.8405, Val Acc: 71.27%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 | Time: 44.49s | Train Loss: 0.4574, Train Acc: 82.74% | Val Loss: 0.9738, Val Acc: 67.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 | Time: 45.59s | Train Loss: 0.4516, Train Acc: 83.06% | Val Loss: 0.9570, Val Acc: 70.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 | Time: 44.69s | Train Loss: 0.4446, Train Acc: 83.37% | Val Loss: 1.4342, Val Acc: 58.08%\n",
            "\n",
            "Reducing learning rate from 1.00e-03 to 2.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100 | Time: 44.98s | Train Loss: 0.3878, Train Acc: 85.44% | Val Loss: 1.5491, Val Acc: 57.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100 | Time: 45.32s | Train Loss: 0.3748, Train Acc: 85.96% | Val Loss: 1.3197, Val Acc: 60.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100 | Time: 45.07s | Train Loss: 0.3661, Train Acc: 86.19% | Val Loss: 1.1632, Val Acc: 64.15%\n",
            "\n",
            "Reducing learning rate from 2.00e-04 to 4.00e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100 | Time: 45.17s | Train Loss: 0.3541, Train Acc: 86.70% | Val Loss: 1.3070, Val Acc: 62.05%\n",
            "\n",
            "Early stopping at epoch 16\n",
            "Restored model weights from the end of the best epoch: 9\n",
            "--- Training Finished ---\n",
            "\n",
            "--- Starting Comprehensive Evaluation on Test Set ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 83/83 [00:02<00:00, 28.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Top-K Accuracy Results ---\n",
            "Top-1 Accuracy: 62.40%\n",
            "Top-3 Accuracy: 90.38%\n",
            "Top-5 Accuracy: 95.57%\n",
            "\n",
            "--- Additional Performance Metrics ---\n",
            "Macro Average Precision: 0.6780\n",
            "Macro Average Recall: 0.6189\n",
            "Macro Average F1-Score: 0.5714\n",
            "Weighted Average Precision: 0.6777\n",
            "Weighted Average Recall: 0.6240\n",
            "Weighted Average F1-Score: 0.5750\n",
            "\n",
            "--- Model Confidence & Calibration Metrics ---\n",
            "Average Prediction Confidence: 0.8376\n",
            "Confidence Standard Deviation: 0.1914\n",
            "Average Prediction Entropy: 0.4844\n",
            "Expected Calibration Error: 0.2137\n",
            "\n",
            "Final Test Loss: 1.2998\n",
            "===============================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "CONFIG = {\n",
        "    \"batch_size\": 128,\n",
        "    \"num_epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"split_seed\": 42,\n",
        "    \"train_split\": 0.70,\n",
        "    \"val_split\": 0.15,\n",
        "    \"test_split\": 0.15,\n",
        "    \"num_classes\": 10,  # Fashion-MNIST has 10 classes\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"checkpoint_path\": \"./best_model.pth\",\n",
        "}\n",
        "\n",
        "# --- Transformer Configuration ---\n",
        "TRANSFORMER_CONFIG = {\n",
        "    \"embedding_dim\": 256,\n",
        "    \"nhead\": 8,\n",
        "    \"num_encoder_layers\": 3,\n",
        "    \"dim_feedforward\": 512,\n",
        "    \"dropout\": 0.1,\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# Callback Classes\n",
        "# ==========================================\n",
        "\n",
        "class Callback:\n",
        "    \"\"\"Base callback class\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_training_end(self):\n",
        "        pass\n",
        "\n",
        "class ReduceLROnPlateau(Callback):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving\"\"\"\n",
        "    def __init__(self, optimizer, monitor='val_accuracy', factor=0.2, patience=3, min_lr=1e-7, verbose=1):\n",
        "        self.optimizer = optimizer\n",
        "        self.monitor = monitor\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                old_lr = self.optimizer.param_groups[0]['lr']\n",
        "                new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "                if new_lr != old_lr:\n",
        "                    self.optimizer.param_groups[0]['lr'] = new_lr\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nReducing learning rate from {old_lr:.2e} to {new_lr:.2e}\")\n",
        "                    self.wait = 0\n",
        "\n",
        "class EarlyStopping(Callback):\n",
        "    \"\"\"Stop training when a monitored metric has stopped improving\"\"\"\n",
        "    def __init__(self, monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1):\n",
        "        self.monitor = monitor\n",
        "        self.patience = patience\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.best_weights = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None:\n",
        "            return False\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return False\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def on_training_end(self, model=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose:\n",
        "            print(f\"Restored model weights from the end of the best epoch: {self.stopped_epoch + 1 - self.patience}\")\n",
        "        if model is not None and self.restore_best_weights and self.best_weights is not None:\n",
        "            model.load_state_dict(self.best_weights)\n",
        "\n",
        "class ModelCheckpoint(Callback):\n",
        "    \"\"\"Save the model after every epoch\"\"\"\n",
        "    def __init__(self, filepath, save_best_only=True, monitor='val_accuracy', verbose=1):\n",
        "        self.filepath = filepath\n",
        "        self.save_best_only = save_best_only\n",
        "        self.monitor = monitor\n",
        "        self.verbose = verbose\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None or model is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if not self.save_best_only:\n",
        "            filepath = self.filepath.replace('.pth', f'_epoch_{epoch + 1}.pth')\n",
        "            torch.save(model.state_dict(), filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "\n",
        "# ==========================================\n",
        "# Data Preprocessing\n",
        "# ==========================================\n",
        "\n",
        "def get_dataloaders(config):\n",
        "    \"\"\"Downloads, prepares, and splits Fashion-MNIST data, returning DataLoaders.\"\"\"\n",
        "\n",
        "    # Data augmentation for training\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=10),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.2860], std=[0.3530]),  # Fashion-MNIST specific normalization\n",
        "    ])\n",
        "\n",
        "    # No augmentation for validation/test\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.2860], std=[0.3530]),  # Fashion-MNIST specific normalization\n",
        "    ])\n",
        "\n",
        "    # Download Fashion-MNIST dataset\n",
        "    print(\"Downloading Fashion-MNIST dataset...\")\n",
        "    train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    test_dataset_original = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=test_transform\n",
        "    )\n",
        "\n",
        "    # Combine train and test datasets for custom splitting\n",
        "    # We need to apply the same transform to the combined dataset for consistency\n",
        "    combined_train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=False,\n",
        "        transform=test_transform  # Use test transform for consistent splitting\n",
        "    )\n",
        "\n",
        "    full_dataset = torch.utils.data.ConcatDataset([combined_train_dataset, test_dataset_original])\n",
        "\n",
        "    # Ensure reproducible splits\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(config[\"train_split\"] * total_size)\n",
        "    val_size = int(config[\"val_split\"] * total_size)\n",
        "    test_size = int(config[\"test_split\"] * total_size)\n",
        "\n",
        "    # Adjust sizes to ensure they sum to total_size (handle rounding issues)\n",
        "    actual_total = train_size + val_size + test_size\n",
        "    if actual_total != total_size:\n",
        "        # Add/subtract the difference to test_size\n",
        "        test_size += (total_size - actual_total)\n",
        "\n",
        "    print(f\"Dataset splits - Train: {train_size}, Val: {val_size}, Test: {test_size}, Total: {total_size}\")\n",
        "\n",
        "    # Create reproducible generator for splitting\n",
        "    generator = torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    train_subset, val_subset, test_subset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size], generator=generator\n",
        "    )\n",
        "\n",
        "    # Create a custom dataset class to apply different transforms to train subset\n",
        "    class TransformSubset(Dataset):\n",
        "        def __init__(self, subset, transform=None):\n",
        "            self.subset = subset\n",
        "            self.transform = transform\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            x, y = self.subset[index]\n",
        "            if self.transform:\n",
        "                # Convert tensor back to PIL Image for transforms\n",
        "                if isinstance(x, torch.Tensor):\n",
        "                    x = transforms.ToPILImage()(x)\n",
        "                x = self.transform(x)\n",
        "            return x, y\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.subset)\n",
        "\n",
        "    # Apply training transforms to training subset\n",
        "    train_subset_with_augment = TransformSubset(train_subset, train_transform)\n",
        "\n",
        "    # Set worker init function for reproducible DataLoader behavior\n",
        "    def worker_init_fn(worker_id):\n",
        "        np.random.seed(config[\"split_seed\"] + worker_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset_with_augment,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# ==========================================\n",
        "# Model Architecture and Training\n",
        "# ==========================================\n",
        "\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    The Rotary Positional Embedding (RoPE) module.\n",
        "    This implementation is based on the paper \"RoFormer: Enhanced Transformer with Rotary Position Embedding\".\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, base=10000):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.base = base\n",
        "        # Create inverse frequencies and register as a buffer\n",
        "        inv_freq = 1.0 / (self.base ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        self.register_buffer(\"inv_freq\", inv_freq)\n",
        "        self.seq_len_cached = None\n",
        "        self.cos_cached = None\n",
        "        self.sin_cached = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.shape[1]\n",
        "        # Check if we need to recompute the cache\n",
        "        if seq_len != self.seq_len_cached:\n",
        "            self.seq_len_cached = seq_len\n",
        "            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)\n",
        "            freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
        "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n",
        "            self.cos_cached = emb.cos()[:, None, :]\n",
        "            self.sin_cached = emb.sin()[:, None, :]\n",
        "\n",
        "        # Apply the rotation\n",
        "        return self.cos_cached, self.sin_cached\n",
        "\n",
        "def rotate_half(x):\n",
        "    x1, x2 = x[..., : x.shape[-1] // 2], x[..., x.shape[-1] // 2 :]\n",
        "    return torch.cat((-x2, x1), dim=x1.ndim - 1)\n",
        "\n",
        "def apply_rotary_pos_emb(q, k, cos, sin):\n",
        "    return (q * cos) + (rotate_half(q) * sin), (k * cos) + (rotate_half(k) * sin)\n",
        "\n",
        "class MultiHeadAttentionWithRoPE(nn.Module):\n",
        "    \"\"\"Custom Multi-Head Attention with RoPE support\"\"\"\n",
        "    def __init__(self, d_model, nhead, dropout=0.1, batch_first=True):\n",
        "        super().__init__()\n",
        "        assert d_model % nhead == 0\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.d_k = d_model // nhead\n",
        "        self.batch_first = batch_first  # Add this attribute\n",
        "\n",
        "        self.w_q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.w_k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.w_v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.rotary_emb = RotaryEmbedding(self.d_k)\n",
        "\n",
        "    def forward(self, query, key, value, key_padding_mask=None, attn_mask=None, need_weights=False, is_causal=False):\n",
        "        batch_size, seq_len, _ = query.size()\n",
        "\n",
        "        # Linear transformations\n",
        "        Q = self.w_q(query)  # [batch_size, seq_len, d_model]\n",
        "        K = self.w_k(key)    # [batch_size, seq_len, d_model]\n",
        "        V = self.w_v(value)  # [batch_size, seq_len, d_model]\n",
        "\n",
        "        # Reshape for multi-head attention\n",
        "        Q = Q.view(batch_size, seq_len, self.nhead, self.d_k)  # [batch, seq, heads, d_k]\n",
        "        K = K.view(batch_size, seq_len, self.nhead, self.d_k)\n",
        "        V = V.view(batch_size, seq_len, self.nhead, self.d_k)\n",
        "\n",
        "        # Apply RoPE to Q and K\n",
        "        cos, sin = self.rotary_emb(query)\n",
        "        Q, K = apply_rotary_pos_emb(Q, K, cos, sin)\n",
        "\n",
        "        # Transpose for attention computation: [batch, heads, seq, d_k]\n",
        "        Q = Q.transpose(1, 2)\n",
        "        K = K.transpose(1, 2)\n",
        "        V = V.transpose(1, 2)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # Apply masks if provided\n",
        "        if attn_mask is not None:\n",
        "            scores = scores.masked_fill(attn_mask == 0, -1e9)\n",
        "\n",
        "        if key_padding_mask is not None:\n",
        "            # key_padding_mask: [batch_size, seq_len], True for padding positions\n",
        "            key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)  # [batch, 1, 1, seq]\n",
        "            scores = scores.masked_fill(key_padding_mask, -1e9)\n",
        "\n",
        "        attention_weights = torch.softmax(scores, dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "        # Apply attention to values\n",
        "        attention_output = torch.matmul(attention_weights, V)  # [batch, heads, seq, d_k]\n",
        "\n",
        "        # Concatenate heads\n",
        "        attention_output = attention_output.transpose(1, 2).contiguous().view(\n",
        "            batch_size, seq_len, self.d_model\n",
        "        )\n",
        "\n",
        "        # Final linear transformation\n",
        "        output = self.w_o(attention_output)\n",
        "\n",
        "        if need_weights:\n",
        "            return output, attention_weights.mean(dim=1)  # Average over heads for compatibility\n",
        "        return output\n",
        "\n",
        "class TransformerEncoderLayerWithRoPE(nn.Module):\n",
        "    \"\"\"\n",
        "    A custom Transformer Encoder Layer that incorporates RoPE.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, nhead, dim_feedforward, dropout, batch_first=True):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttentionWithRoPE(d_model, nhead, dropout, batch_first)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        self.batch_first = batch_first  # Add this attribute\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n",
        "        # Self-attention with RoPE\n",
        "        src2 = self.self_attn(src, src, src, key_padding_mask=src_key_padding_mask, attn_mask=src_mask)\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "\n",
        "        # Feed Forward\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src\n",
        "\n",
        "class NonResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(NonResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNetTransformer(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes, t_config):\n",
        "        super(ResNetTransformer, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.embedding_dim = t_config[\"embedding_dim\"]\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.projections = nn.ModuleList([\n",
        "            self._create_projection(64, self.embedding_dim),\n",
        "            self._create_projection(64, self.embedding_dim),\n",
        "            self._create_projection(128, self.embedding_dim),\n",
        "            self._create_projection(256, self.embedding_dim),\n",
        "            self._create_projection(512, self.embedding_dim)\n",
        "        ])\n",
        "\n",
        "        # Create transformer encoder layers manually\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            TransformerEncoderLayerWithRoPE(\n",
        "                d_model=self.embedding_dim,\n",
        "                nhead=t_config[\"nhead\"],\n",
        "                dim_feedforward=t_config[\"dim_feedforward\"],\n",
        "                dropout=t_config[\"dropout\"],\n",
        "                batch_first=True\n",
        "            ) for _ in range(t_config[\"num_encoder_layers\"])\n",
        "        ])\n",
        "\n",
        "        self.classifier = nn.Linear(self.embedding_dim, num_classes)\n",
        "\n",
        "    def _create_projection(self, in_features, out_features):\n",
        "        return nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, out_features)\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        current_in_channels = self.in_channels\n",
        "        for s in strides:\n",
        "            layers.append(block(current_in_channels, out_channels, s))\n",
        "            current_in_channels = out_channels\n",
        "        self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = []\n",
        "        x = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
        "        features.append(x)\n",
        "        x = self.layer1(x)\n",
        "        features.append(x)\n",
        "        x = self.layer2(x)\n",
        "        features.append(x)\n",
        "        x = self.layer3(x)\n",
        "        features.append(x)\n",
        "        x = self.layer4(x)\n",
        "        features.append(x)\n",
        "\n",
        "        tokens = [self.projections[i](feat) for i, feat in enumerate(features)]\n",
        "        token_sequence = torch.stack(tokens, dim=1)\n",
        "\n",
        "        # Apply transformer layers manually\n",
        "        for layer in self.transformer_layers:\n",
        "            token_sequence = layer(token_sequence)\n",
        "\n",
        "        aggregated_vector = token_sequence.mean(dim=1)\n",
        "        logits = self.classifier(aggregated_vector)\n",
        "        return logits\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, config):\n",
        "    \"\"\"Main training loop with callbacks.\"\"\"\n",
        "    device = config[\"device\"]\n",
        "    model.to(device)\n",
        "\n",
        "    # Set seeds for reproducible training\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(config[\"split_seed\"])\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "    # Initialize callbacks\n",
        "    callbacks = [\n",
        "        ReduceLROnPlateau(\n",
        "            optimizer=optimizer,\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=7,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=config[\"checkpoint_path\"],\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        running_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\", leave=False)\n",
        "        for images, labels in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_loss / train_total\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['num_epochs']} | Time: {time.time() - start_time:.2f}s | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Prepare logs for callbacks\n",
        "        logs = {\n",
        "            'train_loss': train_loss,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc\n",
        "        }\n",
        "\n",
        "        # Execute callbacks\n",
        "        for callback in callbacks:\n",
        "            if isinstance(callback, EarlyStopping):\n",
        "                if callback.on_epoch_end(epoch, logs, model):\n",
        "                    early_stop = True\n",
        "                    break\n",
        "            elif isinstance(callback, ModelCheckpoint):\n",
        "                callback.on_epoch_end(epoch, logs, model)\n",
        "            else:\n",
        "                callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    # Execute callback cleanup\n",
        "    for callback in callbacks:\n",
        "        if isinstance(callback, EarlyStopping):\n",
        "            callback.on_training_end(model)\n",
        "        else:\n",
        "            callback.on_training_end()\n",
        "\n",
        "    print(\"--- Training Finished ---\\n\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "\n",
        "def calculate_top_k_accuracy(outputs, labels, k_values=[1, 3, 5]):\n",
        "    \"\"\"Calculate top-k accuracy for given k values.\"\"\"\n",
        "    batch_size = labels.size(0)\n",
        "    _, pred = outputs.topk(max(k_values), 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "    top_k_accuracies = {}\n",
        "    for k in k_values:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        top_k_accuracies[k] = correct_k.item() / batch_size\n",
        "\n",
        "    return top_k_accuracies\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "    \"\"\"Calculate entropy of probability distributions.\"\"\"\n",
        "    # Add small epsilon to avoid log(0)\n",
        "    epsilon = 1e-8\n",
        "    probs = probs + epsilon\n",
        "    entropy = -torch.sum(probs * torch.log(probs), dim=1)\n",
        "    return entropy\n",
        "\n",
        "def calculate_ece(confidences, accuracies, n_bins=10):\n",
        "    \"\"\"Calculate Expected Calibration Error.\"\"\"\n",
        "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers = bin_boundaries[:-1]\n",
        "    bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    ece = 0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower.item()) & (confidences <= bin_upper.item())\n",
        "        prop_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prop_in_bin.item() > 0:\n",
        "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece.item()\n",
        "\n",
        "def comprehensive_evaluation(model, test_loader, criterion, device):\n",
        "    \"\"\"Comprehensive evaluation with all requested metrics.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_confidences = []\n",
        "    all_entropies = []\n",
        "    all_top_k_results = {1: [], 3: [], 5: []}\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Convert outputs to probabilities\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Get predictions and confidences\n",
        "            confidences, predictions = torch.max(probs, dim=1)\n",
        "\n",
        "            # Calculate entropy\n",
        "            entropies = calculate_entropy(probs)\n",
        "\n",
        "            # Calculate top-k accuracies\n",
        "            top_k_accs = calculate_top_k_accuracy(outputs, labels, [1, 3, 5])\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_entropies.extend(entropies.cpu().numpy())\n",
        "\n",
        "            for k in [1, 3, 5]:\n",
        "                all_top_k_results[k].extend([top_k_accs[k]] * labels.size(0))\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_confidences = np.array(all_confidences)\n",
        "    all_entropies = np.array(all_entropies)\n",
        "\n",
        "    # Calculate basic metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    # Calculate top-k accuracies\n",
        "    top1 = np.mean([pred == label for pred, label in zip(all_predictions, all_labels)])\n",
        "    top3 = np.mean(all_top_k_results[3])\n",
        "    top5 = np.mean(all_top_k_results[5])\n",
        "\n",
        "    # Calculate precision, recall, f1-score\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate confidence and calibration metrics\n",
        "    avg_confidence = np.mean(all_confidences)\n",
        "    std_confidence = np.std(all_confidences)\n",
        "    avg_entropy = np.mean(all_entropies)\n",
        "\n",
        "    # Calculate ECE\n",
        "    accuracies = (all_predictions == all_labels).astype(float)\n",
        "    ece = calculate_ece(torch.tensor(all_confidences), torch.tensor(accuracies))\n",
        "\n",
        "    return {\n",
        "        'test_loss': avg_loss,\n",
        "        'top1': top1,\n",
        "        'top3': top3,\n",
        "        'top5': top5,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_weighted': precision_weighted,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'std_confidence': std_confidence,\n",
        "        'avg_entropy': avg_entropy,\n",
        "        'ece': ece\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# Main Execution\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set global seeds for full reproducibility\n",
        "    torch.manual_seed(CONFIG[\"split_seed\"])\n",
        "    np.random.seed(CONFIG[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(CONFIG[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(CONFIG[\"split_seed\"])\n",
        "        # Ensure deterministic behavior on CUDA\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"Using device: {CONFIG['device']}\")\n",
        "    print(f\"Reproducibility seed: {CONFIG['split_seed']}\")\n",
        "\n",
        "    # Get data loaders\n",
        "    dataloaders = get_dataloaders(CONFIG)\n",
        "    if dataloaders is None:\n",
        "        print(\"Could not prepare data. Halting execution.\", file=sys.stderr)\n",
        "        sys.exit(1)  # Exit if data preparation failed\n",
        "\n",
        "    train_loader, val_loader, test_loader = dataloaders\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = ResNetTransformer(\n",
        "        block=NonResidualBlock,\n",
        "        layers=[2, 2, 2, 2],\n",
        "        num_classes=CONFIG[\"num_classes\"],\n",
        "        t_config=TRANSFORMER_CONFIG\n",
        "    )\n",
        "    trained_model = train_and_validate(model, train_loader, val_loader, CONFIG)\n",
        "\n",
        "    # Comprehensive evaluation on the test set\n",
        "    print(\"--- Starting Comprehensive Evaluation on Test Set ---\")\n",
        "    results = comprehensive_evaluation(trained_model, test_loader, nn.CrossEntropyLoss(), CONFIG[\"device\"])\n",
        "\n",
        "    # Print all requested metrics\n",
        "    print(\"\\n--- Top-K Accuracy Results ---\")\n",
        "    print(f\"Top-1 Accuracy: {results['top1'] * 100:.2f}%\")\n",
        "    print(f\"Top-3 Accuracy: {results['top3'] * 100:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {results['top5'] * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Additional Performance Metrics ---\")\n",
        "    print(f\"Macro Average Precision: {results['precision_macro']:.4f}\")\n",
        "    print(f\"Macro Average Recall: {results['recall_macro']:.4f}\")\n",
        "    print(f\"Macro Average F1-Score: {results['f1_macro']:.4f}\")\n",
        "    print(f\"Weighted Average Precision: {results['precision_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average Recall: {results['recall_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average F1-Score: {results['f1_weighted']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Model Confidence & Calibration Metrics ---\")\n",
        "    print(f\"Average Prediction Confidence: {results['avg_confidence']:.4f}\")\n",
        "    print(f\"Confidence Standard Deviation: {results['std_confidence']:.4f}\")\n",
        "    print(f\"Average Prediction Entropy: {results['avg_entropy']:.4f}\")\n",
        "    print(f\"Expected Calibration Error: {results['ece']:.4f}\")\n",
        "\n",
        "    print(f\"\\nFinal Test Loss: {results['test_loss']:.4f}\")\n",
        "    print(\"===============================================\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}