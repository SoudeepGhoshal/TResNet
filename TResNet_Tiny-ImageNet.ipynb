{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "PoCEg9irkQJs",
        "zfxvXi20RytA",
        "z8zzzKuRR8Bb"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoudeepGhoshal/TResNet/blob/main/TResNet_Tiny-ImageNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tiny ImageNet"
      ],
      "metadata": {
        "id": "_ZS36xhM6OB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet-18"
      ],
      "metadata": {
        "id": "-c-zQogVjys2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65v7OsdRjj7b",
        "outputId": "6651b27e-e2ee-4b47-f11d-24b3ff6e5bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Reproducibility seed: 42\n",
            "Dataset directory already exists.\n",
            "Dataset splits - Train: 77000, Val: 16500, Test: 16500, Total: 110000\n",
            "\n",
            "--- Starting Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Time: 65.55s | Train Loss: 4.4417, Train Acc: 8.14% | Val Loss: 4.0291, Val Acc: 12.84%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 | Time: 54.40s | Train Loss: 3.6114, Train Acc: 18.83% | Val Loss: 3.5136, Val Acc: 20.83%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100 | Time: 52.70s | Train Loss: 3.2187, Train Acc: 25.73% | Val Loss: 3.2694, Val Acc: 25.09%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 | Time: 52.49s | Train Loss: 2.9188, Train Acc: 31.27% | Val Loss: 3.1764, Val Acc: 27.27%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100 | Time: 54.17s | Train Loss: 2.6395, Train Acc: 36.50% | Val Loss: 3.0319, Val Acc: 29.72%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 | Time: 54.26s | Train Loss: 2.3533, Train Acc: 42.05% | Val Loss: 3.0845, Val Acc: 30.70%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100 | Time: 54.16s | Train Loss: 2.0389, Train Acc: 48.57% | Val Loss: 3.0938, Val Acc: 30.76%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 | Time: 53.22s | Train Loss: 1.6773, Train Acc: 56.32% | Val Loss: 3.0481, Val Acc: 32.52%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 | Time: 53.22s | Train Loss: 1.2684, Train Acc: 66.01% | Val Loss: 3.2677, Val Acc: 31.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 | Time: 53.35s | Train Loss: 0.8732, Train Acc: 75.70% | Val Loss: 3.5970, Val Acc: 30.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 | Time: 53.27s | Train Loss: 0.5759, Train Acc: 83.69% | Val Loss: 3.9835, Val Acc: 29.50%\n",
            "\n",
            "Reducing learning rate from 1.00e-03 to 2.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 | Time: 53.63s | Train Loss: 0.1756, Train Acc: 96.31% | Val Loss: 3.7164, Val Acc: 33.64%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100 | Time: 52.71s | Train Loss: 0.0491, Train Acc: 99.75% | Val Loss: 3.8361, Val Acc: 33.84%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100 | Time: 53.26s | Train Loss: 0.0264, Train Acc: 99.95% | Val Loss: 3.9447, Val Acc: 33.91%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100 | Time: 53.66s | Train Loss: 0.0175, Train Acc: 99.97% | Val Loss: 4.0365, Val Acc: 33.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100 | Time: 53.44s | Train Loss: 0.0138, Train Acc: 99.97% | Val Loss: 4.1036, Val Acc: 33.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100 | Time: 53.65s | Train Loss: 0.0113, Train Acc: 99.96% | Val Loss: 4.1634, Val Acc: 33.17%\n",
            "\n",
            "Reducing learning rate from 2.00e-04 to 4.00e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100 | Time: 54.44s | Train Loss: 0.0081, Train Acc: 99.98% | Val Loss: 4.1814, Val Acc: 33.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100 | Time: 54.38s | Train Loss: 0.0063, Train Acc: 99.98% | Val Loss: 4.1896, Val Acc: 33.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100 | Time: 54.01s | Train Loss: 0.0057, Train Acc: 99.97% | Val Loss: 4.1959, Val Acc: 33.48%\n",
            "\n",
            "Reducing learning rate from 4.00e-05 to 8.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100 | Time: 54.01s | Train Loss: 0.0048, Train Acc: 99.98% | Val Loss: 4.1942, Val Acc: 33.46%\n",
            "\n",
            "Early stopping at epoch 21\n",
            "Restored model weights from the end of the best epoch: 14\n",
            "--- Training Finished ---\n",
            "\n",
            "--- Starting Comprehensive Evaluation on Test Set ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 129/129 [00:08<00:00, 14.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Top-K Accuracy Results ---\n",
            "Top-1 Accuracy: 33.21%\n",
            "Top-3 Accuracy: 50.75%\n",
            "Top-5 Accuracy: 58.76%\n",
            "\n",
            "--- Additional Performance Metrics ---\n",
            "Macro Average Precision: 0.3285\n",
            "Macro Average Recall: 0.3311\n",
            "Macro Average F1-Score: 0.3279\n",
            "Weighted Average Precision: 0.3323\n",
            "Weighted Average Recall: 0.3321\n",
            "Weighted Average F1-Score: 0.3304\n",
            "\n",
            "--- Model Confidence & Calibration Metrics ---\n",
            "Average Prediction Confidence: 0.6770\n",
            "Confidence Standard Deviation: 0.2487\n",
            "Average Prediction Entropy: 1.0597\n",
            "Expected Calibration Error: 0.3449\n",
            "\n",
            "Final Test Loss: 4.2113\n",
            "===============================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "CONFIG = {\n",
        "    \"data_path\": \"./tiny-imagenet-200/\",\n",
        "    \"dataset_url\": \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\",\n",
        "    \"batch_size\": 128,\n",
        "    \"num_epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"split_seed\": 42, # Seed for creating reproducible dataset splits\n",
        "    \"train_split\": 0.70,\n",
        "    \"val_split\": 0.15,\n",
        "    \"test_split\": 0.15,  # Explicitly define test split for clarity\n",
        "    \"num_classes\": 200,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"checkpoint_path\": \"./best_model.pth\",  # Added checkpoint path\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# Callback Classes\n",
        "# ==========================================\n",
        "\n",
        "class Callback:\n",
        "    \"\"\"Base callback class\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_training_end(self):\n",
        "        pass\n",
        "\n",
        "class ReduceLROnPlateau(Callback):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving\"\"\"\n",
        "    def __init__(self, optimizer, monitor='val_accuracy', factor=0.2, patience=3, min_lr=1e-7, verbose=1):\n",
        "        self.optimizer = optimizer\n",
        "        self.monitor = monitor\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                old_lr = self.optimizer.param_groups[0]['lr']\n",
        "                new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "                if new_lr != old_lr:\n",
        "                    self.optimizer.param_groups[0]['lr'] = new_lr\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nReducing learning rate from {old_lr:.2e} to {new_lr:.2e}\")\n",
        "                    self.wait = 0\n",
        "\n",
        "class EarlyStopping(Callback):\n",
        "    \"\"\"Stop training when a monitored metric has stopped improving\"\"\"\n",
        "    def __init__(self, monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1):\n",
        "        self.monitor = monitor\n",
        "        self.patience = patience\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.best_weights = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None:\n",
        "            return False\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return False\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def on_training_end(self, model=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose:\n",
        "            print(f\"Restored model weights from the end of the best epoch: {self.stopped_epoch + 1 - self.patience}\")\n",
        "        if model is not None and self.restore_best_weights and self.best_weights is not None:\n",
        "            model.load_state_dict(self.best_weights)\n",
        "\n",
        "class ModelCheckpoint(Callback):\n",
        "    \"\"\"Save the model after every epoch\"\"\"\n",
        "    def __init__(self, filepath, save_best_only=True, monitor='val_accuracy', verbose=1):\n",
        "        self.filepath = filepath\n",
        "        self.save_best_only = save_best_only\n",
        "        self.monitor = monitor\n",
        "        self.verbose = verbose\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None or model is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if not self.save_best_only:\n",
        "            filepath = self.filepath.replace('.pth', f'_epoch_{epoch + 1}.pth')\n",
        "            torch.save(model.state_dict(), filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "\n",
        "# ==========================================\n",
        "# Data Preprocessing\n",
        "# ==========================================\n",
        "\n",
        "def download_and_unzip(url, dest_path):\n",
        "    \"\"\"Downloads and unzips with progress and robust error handling.\"\"\"\n",
        "    if os.path.exists(dest_path):\n",
        "        print(\"Dataset directory already exists.\")\n",
        "        return True\n",
        "\n",
        "    zip_path = dest_path.rstrip('/') + \".zip\"\n",
        "    # The parent directory where we will extract the zip file\n",
        "    extract_to_dir = os.path.abspath(os.path.join(dest_path, os.pardir))\n",
        "\n",
        "    print(f\"Downloading dataset from {url}...\")\n",
        "    try:\n",
        "        with requests.get(url, stream=True, timeout=30) as r:\n",
        "            r.raise_for_status()\n",
        "            total_size = int(r.headers.get('content-length', 0))\n",
        "            with open(zip_path, 'wb') as f, tqdm(\n",
        "                total=total_size, unit='iB', unit_scale=True, desc=\"Tiny ImageNet\"\n",
        "            ) as progress_bar:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "                    progress_bar.update(len(chunk))\n",
        "\n",
        "        print(\"Unzipping...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            # **FIX:** Extract to the parent directory to avoid nested folders\n",
        "            zip_ref.extractall(extract_to_dir)\n",
        "        return True\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError downloading file: {e}\", file=sys.stderr)\n",
        "        print(\"Please check your internet connection or the dataset URL.\", file=sys.stderr)\n",
        "        return False\n",
        "\n",
        "    finally:\n",
        "        if os.path.exists(zip_path):\n",
        "            os.remove(zip_path) # Clean up the zip file\n",
        "\n",
        "def prepare_val_folder(val_dir):\n",
        "    \"\"\"Formats the validation folder to be compatible with ImageFolder.\"\"\"\n",
        "    val_annotations_path = os.path.join(val_dir, 'val_annotations.txt')\n",
        "    if not os.path.exists(val_annotations_path):\n",
        "        return # Already formatted\n",
        "\n",
        "    print(\"Formatting validation folder...\")\n",
        "    val_img_dir = os.path.join(val_dir, 'images')\n",
        "    val_img_dict = {}\n",
        "    with open(val_annotations_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split('\\t')\n",
        "            img_name, class_id = parts[0], parts[1]\n",
        "            val_img_dict[img_name] = class_id\n",
        "\n",
        "    for img_name, class_id in val_img_dict.items():\n",
        "        class_dir = os.path.join(val_dir, class_id)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        src_path = os.path.join(val_img_dir, img_name)\n",
        "        if os.path.exists(src_path):\n",
        "            shutil.move(src_path, os.path.join(class_dir, img_name))\n",
        "\n",
        "    if os.path.exists(val_annotations_path):\n",
        "        os.remove(val_annotations_path)\n",
        "    if os.path.exists(val_img_dir):\n",
        "        shutil.rmtree(val_img_dir)\n",
        "\n",
        "def get_dataloaders(config):\n",
        "    \"\"\"Downloads, prepares, and splits the data, returning DataLoaders.\"\"\"\n",
        "    if not download_and_unzip(config[\"dataset_url\"], config[\"data_path\"]):\n",
        "        return None # Return None if download fails\n",
        "\n",
        "    train_dir = os.path.join(config[\"data_path\"], 'train')\n",
        "    val_dir = os.path.join(config[\"data_path\"], 'val')\n",
        "    prepare_val_folder(val_dir)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    train_dataset = ImageFolder(train_dir, transform=transform)\n",
        "    val_dataset_original = ImageFolder(val_dir, transform=transform)\n",
        "    full_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset_original])\n",
        "\n",
        "    # Ensure reproducible splits\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(config[\"train_split\"] * total_size)\n",
        "    val_size = int(config[\"val_split\"] * total_size)\n",
        "    test_size = int(config[\"test_split\"] * total_size)\n",
        "\n",
        "    # Adjust sizes to ensure they sum to total_size (handle rounding issues)\n",
        "    actual_total = train_size + val_size + test_size\n",
        "    if actual_total != total_size:\n",
        "        # Add/subtract the difference to test_size\n",
        "        test_size += (total_size - actual_total)\n",
        "\n",
        "    print(f\"Dataset splits - Train: {train_size}, Val: {val_size}, Test: {test_size}, Total: {total_size}\")\n",
        "\n",
        "    # Create reproducible generator for splitting\n",
        "    generator = torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    train_subset, val_subset, test_subset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size], generator=generator\n",
        "    )\n",
        "\n",
        "    # Set worker init function for reproducible DataLoader behavior\n",
        "    def worker_init_fn(worker_id):\n",
        "        np.random.seed(config[\"split_seed\"] + worker_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# ==========================================\n",
        "# Model Architecture and Training\n",
        "# ==========================================\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"A residual block, the fundamental building block of ResNet.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        # Main path\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut path (for matching dimensions)\n",
        "        self.downsample = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.downsample(x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"A modular ResNet implementation.\"\"\"\n",
        "    def __init__(self, block, layers, num_classes=200):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for s in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, s))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def ResNet18(num_classes=200):\n",
        "    return ResNet(ResidualBlock, [2, 2, 2, 2], num_classes)\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, config):\n",
        "    \"\"\"Main training loop with callbacks.\"\"\"\n",
        "    device = config[\"device\"]\n",
        "    model.to(device)\n",
        "\n",
        "    # Set seeds for reproducible training\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(config[\"split_seed\"])\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "    # Initialize callbacks\n",
        "    callbacks = [\n",
        "        ReduceLROnPlateau(\n",
        "            optimizer=optimizer,\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=7,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=config[\"checkpoint_path\"],\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        running_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\", leave=False)\n",
        "        for images, labels in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_loss / train_total\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['num_epochs']} | Time: {time.time() - start_time:.2f}s | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Prepare logs for callbacks\n",
        "        logs = {\n",
        "            'train_loss': train_loss,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc\n",
        "        }\n",
        "\n",
        "        # Execute callbacks\n",
        "        for callback in callbacks:\n",
        "            if isinstance(callback, EarlyStopping):\n",
        "                if callback.on_epoch_end(epoch, logs, model):\n",
        "                    early_stop = True\n",
        "                    break\n",
        "            elif isinstance(callback, ModelCheckpoint):\n",
        "                callback.on_epoch_end(epoch, logs, model)\n",
        "            else:\n",
        "                callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    # Execute callback cleanup\n",
        "    for callback in callbacks:\n",
        "        if isinstance(callback, EarlyStopping):\n",
        "            callback.on_training_end(model)\n",
        "        else:\n",
        "            callback.on_training_end()\n",
        "\n",
        "    print(\"--- Training Finished ---\\n\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "\n",
        "def calculate_top_k_accuracy(outputs, labels, k_values=[1, 3, 5]):\n",
        "    \"\"\"Calculate top-k accuracy for given k values.\"\"\"\n",
        "    batch_size = labels.size(0)\n",
        "    _, pred = outputs.topk(max(k_values), 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "    top_k_accuracies = {}\n",
        "    for k in k_values:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        top_k_accuracies[k] = correct_k.item() / batch_size\n",
        "\n",
        "    return top_k_accuracies\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "    \"\"\"Calculate entropy of probability distributions.\"\"\"\n",
        "    # Add small epsilon to avoid log(0)\n",
        "    epsilon = 1e-8\n",
        "    probs = probs + epsilon\n",
        "    entropy = -torch.sum(probs * torch.log(probs), dim=1)\n",
        "    return entropy\n",
        "\n",
        "def calculate_ece(confidences, accuracies, n_bins=10):\n",
        "    \"\"\"Calculate Expected Calibration Error.\"\"\"\n",
        "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers = bin_boundaries[:-1]\n",
        "    bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    ece = 0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower.item()) & (confidences <= bin_upper.item())\n",
        "        prop_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prop_in_bin.item() > 0:\n",
        "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece.item()\n",
        "\n",
        "def comprehensive_evaluation(model, test_loader, criterion, device):\n",
        "    \"\"\"Comprehensive evaluation with all requested metrics.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_confidences = []\n",
        "    all_entropies = []\n",
        "    all_top_k_results = {1: [], 3: [], 5: []}\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Convert outputs to probabilities\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Get predictions and confidences\n",
        "            confidences, predictions = torch.max(probs, dim=1)\n",
        "\n",
        "            # Calculate entropy\n",
        "            entropies = calculate_entropy(probs)\n",
        "\n",
        "            # Calculate top-k accuracies\n",
        "            top_k_accs = calculate_top_k_accuracy(outputs, labels, [1, 3, 5])\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_entropies.extend(entropies.cpu().numpy())\n",
        "\n",
        "            for k in [1, 3, 5]:\n",
        "                all_top_k_results[k].extend([top_k_accs[k]] * labels.size(0))\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_confidences = np.array(all_confidences)\n",
        "    all_entropies = np.array(all_entropies)\n",
        "\n",
        "    # Calculate basic metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    # Calculate top-k accuracies\n",
        "    top1 = np.mean([pred == label for pred, label in zip(all_predictions, all_labels)])\n",
        "    top3 = np.mean(all_top_k_results[3])\n",
        "    top5 = np.mean(all_top_k_results[5])\n",
        "\n",
        "    # Calculate precision, recall, f1-score\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate confidence and calibration metrics\n",
        "    avg_confidence = np.mean(all_confidences)\n",
        "    std_confidence = np.std(all_confidences)\n",
        "    avg_entropy = np.mean(all_entropies)\n",
        "\n",
        "    # Calculate ECE\n",
        "    accuracies = (all_predictions == all_labels).astype(float)\n",
        "    ece = calculate_ece(torch.tensor(all_confidences), torch.tensor(accuracies))\n",
        "\n",
        "    return {\n",
        "        'test_loss': avg_loss,\n",
        "        'top1': top1,\n",
        "        'top3': top3,\n",
        "        'top5': top5,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_weighted': precision_weighted,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'std_confidence': std_confidence,\n",
        "        'avg_entropy': avg_entropy,\n",
        "        'ece': ece\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# Main Execution\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set global seeds for full reproducibility\n",
        "    torch.manual_seed(CONFIG[\"split_seed\"])\n",
        "    np.random.seed(CONFIG[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(CONFIG[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(CONFIG[\"split_seed\"])\n",
        "        # Ensure deterministic behavior on CUDA\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"Using device: {CONFIG['device']}\")\n",
        "    print(f\"Reproducibility seed: {CONFIG['split_seed']}\")\n",
        "\n",
        "    # Get data loaders\n",
        "    dataloaders = get_dataloaders(CONFIG)\n",
        "    if dataloaders is None:\n",
        "        print(\"Could not prepare data. Halting execution.\", file=sys.stderr)\n",
        "        sys.exit(1) # Exit if data preparation failed\n",
        "\n",
        "    train_loader, val_loader, test_loader = dataloaders\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = ResNet18(num_classes=CONFIG[\"num_classes\"])\n",
        "    trained_model = train_and_validate(model, train_loader, val_loader, CONFIG)\n",
        "\n",
        "    # Comprehensive evaluation on the test set\n",
        "    print(\"--- Starting Comprehensive Evaluation on Test Set ---\")\n",
        "    results = comprehensive_evaluation(trained_model, test_loader, nn.CrossEntropyLoss(), CONFIG[\"device\"])\n",
        "\n",
        "    # Print all requested metrics\n",
        "    print(\"\\n--- Top-K Accuracy Results ---\")\n",
        "    print(f\"Top-1 Accuracy: {results['top1'] * 100:.2f}%\")\n",
        "    print(f\"Top-3 Accuracy: {results['top3'] * 100:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {results['top5'] * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Additional Performance Metrics ---\")\n",
        "    print(f\"Macro Average Precision: {results['precision_macro']:.4f}\")\n",
        "    print(f\"Macro Average Recall: {results['recall_macro']:.4f}\")\n",
        "    print(f\"Macro Average F1-Score: {results['f1_macro']:.4f}\")\n",
        "    print(f\"Weighted Average Precision: {results['precision_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average Recall: {results['recall_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average F1-Score: {results['f1_weighted']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Model Confidence & Calibration Metrics ---\")\n",
        "    print(f\"Average Prediction Confidence: {results['avg_confidence']:.4f}\")\n",
        "    print(f\"Confidence Standard Deviation: {results['std_confidence']:.4f}\")\n",
        "    print(f\"Average Prediction Entropy: {results['avg_entropy']:.4f}\")\n",
        "    print(f\"Expected Calibration Error: {results['ece']:.4f}\")\n",
        "\n",
        "    print(f\"\\nFinal Test Loss: {results['test_loss']:.4f}\")\n",
        "    print(\"===============================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Transformer on ResNet-18 (No PE)"
      ],
      "metadata": {
        "id": "z8zzzKuRR8Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "CONFIG = {\n",
        "    \"data_path\": \"./tiny-imagenet-200/\",\n",
        "    \"dataset_url\": \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\",\n",
        "    \"batch_size\": 128,\n",
        "    \"num_epochs\": 50,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"split_seed\": 42,  # Seed for creating reproducible dataset splits\n",
        "    \"train_split\": 0.70,\n",
        "    \"val_split\": 0.15,\n",
        "    \"test_split\": 0.15,  # Explicitly define test split for clarity\n",
        "    \"num_classes\": 200,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"checkpoint_path\": \"./best_model.pth\",  # Added checkpoint path\n",
        "}\n",
        "\n",
        "# --- Transformer Configuration ---\n",
        "TRANSFORMER_CONFIG = {\n",
        "    \"embedding_dim\": 32,\n",
        "    \"nhead\": 16,\n",
        "    \"num_encoder_layers\": 3,\n",
        "    \"dim_feedforward\": 2,\n",
        "    \"dropout\": 0.1,\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# Callback Classes\n",
        "# ==========================================\n",
        "\n",
        "class Callback:\n",
        "    \"\"\"Base callback class\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_training_end(self):\n",
        "        pass\n",
        "\n",
        "class ReduceLROnPlateau(Callback):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving\"\"\"\n",
        "    def __init__(self, optimizer, monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7, verbose=1):\n",
        "        self.optimizer = optimizer\n",
        "        self.monitor = monitor\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                old_lr = self.optimizer.param_groups[0]['lr']\n",
        "                new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "                if new_lr != old_lr:\n",
        "                    self.optimizer.param_groups[0]['lr'] = new_lr\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nReducing learning rate from {old_lr:.2e} to {new_lr:.2e}\")\n",
        "                    self.wait = 0\n",
        "\n",
        "class EarlyStopping(Callback):\n",
        "    \"\"\"Stop training when a monitored metric has stopped improving\"\"\"\n",
        "    def __init__(self, monitor='val_loss', patience=7, restore_best_weights=True, verbose=1):\n",
        "        self.monitor = monitor\n",
        "        self.patience = patience\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.best_weights = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None:\n",
        "            return False\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return False\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def on_training_end(self, model=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose:\n",
        "            print(f\"Restored model weights from the end of the best epoch: {self.stopped_epoch + 1 - self.patience}\")\n",
        "        if model is not None and self.restore_best_weights and self.best_weights is not None:\n",
        "            model.load_state_dict(self.best_weights)\n",
        "\n",
        "class ModelCheckpoint(Callback):\n",
        "    \"\"\"Save the model after every epoch\"\"\"\n",
        "    def __init__(self, filepath, save_best_only=True, monitor='val_accuracy', verbose=1):\n",
        "        self.filepath = filepath\n",
        "        self.save_best_only = save_best_only\n",
        "        self.monitor = monitor\n",
        "        self.verbose = verbose\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None or model is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if not self.save_best_only:\n",
        "            filepath = self.filepath.replace('.pth', f'_epoch_{epoch + 1}.pth')\n",
        "            torch.save(model.state_dict(), filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "\n",
        "# ==========================================\n",
        "# Data Preprocessing\n",
        "# ==========================================\n",
        "\n",
        "def download_and_unzip(url, dest_path):\n",
        "    \"\"\"Downloads and unzips with progress and robust error handling.\"\"\"\n",
        "    if os.path.exists(dest_path):\n",
        "        print(\"Dataset directory already exists.\")\n",
        "        return True\n",
        "\n",
        "    zip_path = dest_path.rstrip('/') + \".zip\"\n",
        "    # The parent directory where we will extract the zip file\n",
        "    extract_to_dir = os.path.abspath(os.path.join(dest_path, os.pardir))\n",
        "\n",
        "    print(f\"Downloading dataset from {url}...\")\n",
        "    try:\n",
        "        with requests.get(url, stream=True, timeout=30) as r:\n",
        "            r.raise_for_status()\n",
        "            total_size = int(r.headers.get('content-length', 0))\n",
        "            with open(zip_path, 'wb') as f, tqdm(\n",
        "                total=total_size, unit='iB', unit_scale=True, desc=\"Tiny ImageNet\"\n",
        "            ) as progress_bar:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "                    progress_bar.update(len(chunk))\n",
        "\n",
        "        print(\"Unzipping...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            # **FIX:** Extract to the parent directory to avoid nested folders\n",
        "            zip_ref.extractall(extract_to_dir)\n",
        "        return True\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError downloading file: {e}\", file=sys.stderr)\n",
        "        print(\"Please check your internet connection or the dataset URL.\", file=sys.stderr)\n",
        "        return False\n",
        "\n",
        "    finally:\n",
        "        if os.path.exists(zip_path):\n",
        "            os.remove(zip_path)  # Clean up the zip file\n",
        "\n",
        "def prepare_val_folder(val_dir):\n",
        "    \"\"\"Formats the validation folder to be compatible with ImageFolder.\"\"\"\n",
        "    val_annotations_path = os.path.join(val_dir, 'val_annotations.txt')\n",
        "    if not os.path.exists(val_annotations_path):\n",
        "        return  # Already formatted\n",
        "\n",
        "    print(\"Formatting validation folder...\")\n",
        "    val_img_dir = os.path.join(val_dir, 'images')\n",
        "    val_img_dict = {}\n",
        "    with open(val_annotations_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split('\\t')\n",
        "            img_name, class_id = parts[0], parts[1]\n",
        "            val_img_dict[img_name] = class_id\n",
        "\n",
        "    for img_name, class_id in val_img_dict.items():\n",
        "        class_dir = os.path.join(val_dir, class_id)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        src_path = os.path.join(val_img_dir, img_name)\n",
        "        if os.path.exists(src_path):\n",
        "            shutil.move(src_path, os.path.join(class_dir, img_name))\n",
        "\n",
        "    if os.path.exists(val_annotations_path):\n",
        "        os.remove(val_annotations_path)\n",
        "    if os.path.exists(val_img_dir):\n",
        "        shutil.rmtree(val_img_dir)\n",
        "\n",
        "def get_dataloaders(config):\n",
        "    \"\"\"Downloads, prepares, and splits the data, returning DataLoaders.\"\"\"\n",
        "    if not download_and_unzip(config[\"dataset_url\"], config[\"data_path\"]):\n",
        "        return None  # Return None if download fails\n",
        "\n",
        "    train_dir = os.path.join(config[\"data_path\"], 'train')\n",
        "    val_dir = os.path.join(config[\"data_path\"], 'val')\n",
        "    prepare_val_folder(val_dir)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    train_dataset = ImageFolder(train_dir, transform=transform)\n",
        "    val_dataset_original = ImageFolder(val_dir, transform=transform)\n",
        "    full_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset_original])\n",
        "\n",
        "    # Ensure reproducible splits\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(config[\"train_split\"] * total_size)\n",
        "    val_size = int(config[\"val_split\"] * total_size)\n",
        "    test_size = int(config[\"test_split\"] * total_size)\n",
        "\n",
        "    # Adjust sizes to ensure they sum to total_size (handle rounding issues)\n",
        "    actual_total = train_size + val_size + test_size\n",
        "    if actual_total != total_size:\n",
        "        # Add/subtract the difference to test_size\n",
        "        test_size += (total_size - actual_total)\n",
        "\n",
        "    print(f\"Dataset splits - Train: {train_size}, Val: {val_size}, Test: {test_size}, Total: {total_size}\")\n",
        "\n",
        "    # Create reproducible generator for splitting\n",
        "    generator = torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    train_subset, val_subset, test_subset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size], generator=generator\n",
        "    )\n",
        "\n",
        "    # Set worker init function for reproducible DataLoader behavior\n",
        "    def worker_init_fn(worker_id):\n",
        "        np.random.seed(config[\"split_seed\"] + worker_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# ==========================================\n",
        "# Model Architecture and Training\n",
        "# ==========================================\n",
        "\n",
        "class NonResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    This block is a standard convolutional block WITHOUT the residual connection.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(NonResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNetTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    A hybrid architecture combining a non-residual CNN backbone with a Transformer encoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, block, layers, num_classes, t_config):\n",
        "        super(ResNetTransformer, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.embedding_dim = t_config[\"embedding_dim\"]\n",
        "\n",
        "        # 1. CNN Backbone (Feature Extractor)\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        # 2. Projection heads to create tokens from feature maps\n",
        "        self.projections = nn.ModuleList([\n",
        "            self._create_projection(64, self.embedding_dim),   # From initial maxpool\n",
        "            self._create_projection(64, self.embedding_dim),   # From layer1\n",
        "            self._create_projection(128, self.embedding_dim),  # From layer2\n",
        "            self._create_projection(256, self.embedding_dim),  # From layer3\n",
        "            self._create_projection(512, self.embedding_dim)   # From layer4\n",
        "        ])\n",
        "\n",
        "        # 3. Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=self.embedding_dim,\n",
        "            nhead=t_config[\"nhead\"],\n",
        "            dim_feedforward=t_config[\"dim_feedforward\"],\n",
        "            dropout=t_config[\"dropout\"],\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=t_config[\"num_encoder_layers\"]\n",
        "        )\n",
        "\n",
        "        # 4. Final Classifier\n",
        "        self.classifier = nn.Linear(self.embedding_dim, num_classes)\n",
        "\n",
        "    def _create_projection(self, in_features, out_features):\n",
        "        return nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, out_features)\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        current_in_channels = self.in_channels\n",
        "        for s in strides:\n",
        "            layers.append(block(current_in_channels, out_channels, s))\n",
        "            current_in_channels = out_channels\n",
        "        self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Pass through CNN backbone and capture features\n",
        "        features = []\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        features.append(x)\n",
        "\n",
        "        x = self.layer1(x); features.append(x)\n",
        "        x = self.layer2(x); features.append(x)\n",
        "        x = self.layer3(x); features.append(x)\n",
        "        x = self.layer4(x); features.append(x)\n",
        "\n",
        "        # 2. Project features to tokens\n",
        "        tokens = []\n",
        "        for i, feature_map in enumerate(features):\n",
        "            tokens.append(self.projections[i](feature_map))\n",
        "\n",
        "        # 3. Stack tokens and pass through Transformer\n",
        "        token_sequence = torch.stack(tokens, dim=1)\n",
        "        transformer_out = self.transformer_encoder(token_sequence)\n",
        "\n",
        "        # 4. Aggregate and classify\n",
        "        aggregated_vector = transformer_out.mean(dim=1)\n",
        "        logits = self.classifier(aggregated_vector)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def ResNetTransformer18(num_classes=200, t_config=TRANSFORMER_CONFIG):\n",
        "    return ResNetTransformer(NonResidualBlock, [2, 2, 2, 2], num_classes, t_config)\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, config):\n",
        "    \"\"\"Main training loop with callbacks.\"\"\"\n",
        "    device = config[\"device\"]\n",
        "    model.to(device)\n",
        "\n",
        "    # Set seeds for reproducible training\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(config[\"split_seed\"])\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "    # Initialize callbacks\n",
        "    callbacks = [\n",
        "        ReduceLROnPlateau(\n",
        "            optimizer=optimizer,\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=7,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=config[\"checkpoint_path\"],\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        running_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\", leave=False)\n",
        "        for images, labels in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_loss / train_total\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['num_epochs']} | Time: {time.time() - start_time:.2f}s | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Prepare logs for callbacks\n",
        "        logs = {\n",
        "            'train_loss': train_loss,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc\n",
        "        }\n",
        "\n",
        "        # Execute callbacks\n",
        "        for callback in callbacks:\n",
        "            if isinstance(callback, EarlyStopping):\n",
        "                if callback.on_epoch_end(epoch, logs, model):\n",
        "                    early_stop = True\n",
        "                    break\n",
        "            elif isinstance(callback, ModelCheckpoint):\n",
        "                callback.on_epoch_end(epoch, logs, model)\n",
        "            else:\n",
        "                callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    # Execute callback cleanup\n",
        "    for callback in callbacks:\n",
        "        if isinstance(callback, EarlyStopping):\n",
        "            callback.on_training_end(model)\n",
        "        else:\n",
        "            callback.on_training_end()\n",
        "\n",
        "    print(\"--- Training Finished ---\\n\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "\n",
        "def calculate_top_k_accuracy(outputs, labels, k_values=[1, 3, 5]):\n",
        "    \"\"\"Calculate top-k accuracy for given k values.\"\"\"\n",
        "    batch_size = labels.size(0)\n",
        "    _, pred = outputs.topk(max(k_values), 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "    top_k_accuracies = {}\n",
        "    for k in k_values:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        top_k_accuracies[k] = correct_k.item() / batch_size\n",
        "\n",
        "    return top_k_accuracies\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "    \"\"\"Calculate entropy of probability distributions.\"\"\"\n",
        "    # Add small epsilon to avoid log(0)\n",
        "    epsilon = 1e-8\n",
        "    probs = probs + epsilon\n",
        "    entropy = -torch.sum(probs * torch.log(probs), dim=1)\n",
        "    return entropy\n",
        "\n",
        "def calculate_ece(confidences, accuracies, n_bins=10):\n",
        "    \"\"\"Calculate Expected Calibration Error.\"\"\"\n",
        "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers = bin_boundaries[:-1]\n",
        "    bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    ece = 0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower.item()) & (confidences <= bin_upper.item())\n",
        "        prop_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prop_in_bin.item() > 0:\n",
        "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece.item()\n",
        "\n",
        "def comprehensive_evaluation(model, test_loader, criterion, device):\n",
        "    \"\"\"Comprehensive evaluation with all requested metrics.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_confidences = []\n",
        "    all_entropies = []\n",
        "    all_top_k_results = {1: [], 3: [], 5: []}\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Convert outputs to probabilities\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Get predictions and confidences\n",
        "            confidences, predictions = torch.max(probs, dim=1)\n",
        "\n",
        "            # Calculate entropy\n",
        "            entropies = calculate_entropy(probs)\n",
        "\n",
        "            # Calculate top-k accuracies\n",
        "            top_k_accs = calculate_top_k_accuracy(outputs, labels, [1, 3, 5])\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_entropies.extend(entropies.cpu().numpy())\n",
        "\n",
        "            for k in [1, 3, 5]:\n",
        "                all_top_k_results[k].extend([top_k_accs[k]] * labels.size(0))\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_confidences = np.array(all_confidences)\n",
        "    all_entropies = np.array(all_entropies)\n",
        "\n",
        "    # Calculate basic metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    # Calculate top-k accuracies\n",
        "    top1 = np.mean([pred == label for pred, label in zip(all_predictions, all_labels)])\n",
        "    top3 = np.mean(all_top_k_results[3])\n",
        "    top5 = np.mean(all_top_k_results[5])\n",
        "\n",
        "    # Calculate precision, recall, f1-score\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate confidence and calibration metrics\n",
        "    avg_confidence = np.mean(all_confidences)\n",
        "    std_confidence = np.std(all_confidences)\n",
        "    avg_entropy = np.mean(all_entropies)\n",
        "\n",
        "    # Calculate ECE\n",
        "    accuracies = (all_predictions == all_labels).astype(float)\n",
        "    ece = calculate_ece(torch.tensor(all_confidences), torch.tensor(accuracies))\n",
        "\n",
        "    return {\n",
        "        'test_loss': avg_loss,\n",
        "        'top1': top1,\n",
        "        'top3': top3,\n",
        "        'top5': top5,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_weighted': precision_weighted,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'std_confidence': std_confidence,\n",
        "        'avg_entropy': avg_entropy,\n",
        "        'ece': ece\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# Main Execution\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set global seeds for full reproducibility\n",
        "    torch.manual_seed(CONFIG[\"split_seed\"])\n",
        "    np.random.seed(CONFIG[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(CONFIG[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(CONFIG[\"split_seed\"])\n",
        "        # Ensure deterministic behavior on CUDA\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"Using device: {CONFIG['device']}\")\n",
        "    print(f\"Reproducibility seed: {CONFIG['split_seed']}\")\n",
        "\n",
        "    # Get data loaders\n",
        "    dataloaders = get_dataloaders(CONFIG)\n",
        "    if dataloaders is None:\n",
        "        print(\"Could not prepare data. Halting execution.\", file=sys.stderr)\n",
        "        sys.exit(1)  # Exit if data preparation failed\n",
        "\n",
        "    train_loader, val_loader, test_loader = dataloaders\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = ResNetTransformer18(num_classes=CONFIG[\"num_classes\"], t_config=TRANSFORMER_CONFIG)\n",
        "    trained_model = train_and_validate(model, train_loader, val_loader, CONFIG)\n",
        "\n",
        "    # Comprehensive evaluation on the test set\n",
        "    print(\"--- Starting Comprehensive Evaluation on Test Set ---\")\n",
        "    results = comprehensive_evaluation(trained_model, test_loader, nn.CrossEntropyLoss(), CONFIG[\"device\"])\n",
        "\n",
        "    # Print all requested metrics\n",
        "    print(\"\\n--- Top-K Accuracy Results ---\")\n",
        "    print(f\"Top-1 Accuracy: {results['top1'] * 100:.2f}%\")\n",
        "    print(f\"Top-3 Accuracy: {results['top3'] * 100:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {results['top5'] * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Additional Performance Metrics ---\")\n",
        "    print(f\"Macro Average Precision: {results['precision_macro']:.4f}\")\n",
        "    print(f\"Macro Average Recall: {results['recall_macro']:.4f}\")\n",
        "    print(f\"Macro Average F1-Score: {results['f1_macro']:.4f}\")\n",
        "    print(f\"Weighted Average Precision: {results['precision_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average Recall: {results['recall_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average F1-Score: {results['f1_weighted']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Model Confidence & Calibration Metrics ---\")\n",
        "    print(f\"Average Prediction Confidence: {results['avg_confidence']:.4f}\")\n",
        "    print(f\"Confidence Standard Deviation: {results['std_confidence']:.4f}\")\n",
        "    print(f\"Average Prediction Entropy: {results['avg_entropy']:.4f}\")\n",
        "    print(f\"Expected Calibration Error: {results['ece']:.4f}\")\n",
        "\n",
        "    print(f\"\\nFinal Test Loss: {results['test_loss']:.4f}\")\n",
        "    print(\"===============================================\")"
      ],
      "metadata": {
        "id": "N7BWUntjplMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca50232-229c-471a-c73e-e719c5656ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Reproducibility seed: 42\n",
            "Dataset directory already exists.\n",
            "Dataset splits - Train: 77000, Val: 16500, Test: 16500, Total: 110000\n",
            "\n",
            "--- Starting Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | Time: 56.04s | Train Loss: 4.9006, Train Acc: 3.08% | Val Loss: 4.6179, Val Acc: 5.46%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50 | Time: 55.80s | Train Loss: 4.3391, Train Acc: 7.92% | Val Loss: 4.1335, Val Acc: 10.38%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50 | Time: 56.66s | Train Loss: 4.0144, Train Acc: 12.00% | Val Loss: 3.9501, Val Acc: 13.52%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50 | Time: 55.65s | Train Loss: 3.8190, Train Acc: 14.70% | Val Loss: 3.8424, Val Acc: 14.93%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50 | Time: 56.26s | Train Loss: 3.6643, Train Acc: 17.06% | Val Loss: 3.6914, Val Acc: 16.62%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50 | Time: 56.26s | Train Loss: 3.5368, Train Acc: 19.23% | Val Loss: 3.5540, Val Acc: 19.01%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50 | Time: 55.55s | Train Loss: 3.4375, Train Acc: 21.01% | Val Loss: 3.5422, Val Acc: 19.40%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50 | Time: 54.55s | Train Loss: 3.3411, Train Acc: 22.82% | Val Loss: 3.3462, Val Acc: 23.19%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50 | Time: 55.40s | Train Loss: 3.2473, Train Acc: 24.33% | Val Loss: 3.3073, Val Acc: 23.66%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50 | Time: 54.45s | Train Loss: 3.1657, Train Acc: 25.84% | Val Loss: 3.2600, Val Acc: 24.76%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50 | Time: 54.94s | Train Loss: 3.0931, Train Acc: 27.24% | Val Loss: 3.2149, Val Acc: 26.15%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50 | Time: 54.98s | Train Loss: 3.0221, Train Acc: 28.54% | Val Loss: 3.1643, Val Acc: 27.07%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50 | Time: 55.12s | Train Loss: 2.9577, Train Acc: 29.66% | Val Loss: 3.0988, Val Acc: 28.00%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50 | Time: 54.81s | Train Loss: 2.8902, Train Acc: 31.24% | Val Loss: 3.0929, Val Acc: 28.45%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50 | Time: 54.37s | Train Loss: 2.8249, Train Acc: 32.45% | Val Loss: 3.0697, Val Acc: 28.70%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50 | Time: 54.84s | Train Loss: 2.7676, Train Acc: 33.61% | Val Loss: 3.0869, Val Acc: 28.75%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50 | Time: 55.28s | Train Loss: 2.7072, Train Acc: 34.77% | Val Loss: 2.9764, Val Acc: 30.65%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50 | Time: 54.85s | Train Loss: 2.6429, Train Acc: 36.25% | Val Loss: 3.0122, Val Acc: 30.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50 | Time: 54.48s | Train Loss: 2.5888, Train Acc: 37.04% | Val Loss: 3.0357, Val Acc: 30.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50 | Time: 55.72s | Train Loss: 2.5263, Train Acc: 38.35% | Val Loss: 2.9399, Val Acc: 31.93%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50 | Time: 54.98s | Train Loss: 2.4685, Train Acc: 39.34% | Val Loss: 2.9420, Val Acc: 31.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50 | Time: 54.81s | Train Loss: 2.4074, Train Acc: 40.72% | Val Loss: 2.9768, Val Acc: 31.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50 | Time: 54.67s | Train Loss: 2.3498, Train Acc: 41.71% | Val Loss: 3.0017, Val Acc: 31.55%\n",
            "\n",
            "Reducing learning rate from 1.00e-03 to 2.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50 | Time: 55.57s | Train Loss: 2.0038, Train Acc: 49.34% | Val Loss: 2.8487, Val Acc: 35.18%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50 | Time: 54.89s | Train Loss: 1.9012, Train Acc: 51.68% | Val Loss: 2.8873, Val Acc: 34.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50 | Time: 54.41s | Train Loss: 1.8380, Train Acc: 52.93% | Val Loss: 2.9316, Val Acc: 34.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50 | Time: 54.53s | Train Loss: 1.7778, Train Acc: 54.18% | Val Loss: 2.9733, Val Acc: 34.32%\n",
            "\n",
            "Reducing learning rate from 2.00e-04 to 4.00e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50 | Time: 55.60s | Train Loss: 1.6570, Train Acc: 57.07% | Val Loss: 2.9845, Val Acc: 34.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50 | Time: 54.76s | Train Loss: 1.6284, Train Acc: 57.86% | Val Loss: 3.0074, Val Acc: 34.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50 | Time: 54.44s | Train Loss: 1.6072, Train Acc: 58.25% | Val Loss: 3.0217, Val Acc: 34.10%\n",
            "\n",
            "Reducing learning rate from 4.00e-05 to 8.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50 | Time: 54.79s | Train Loss: 1.5796, Train Acc: 58.96% | Val Loss: 3.0313, Val Acc: 33.84%\n",
            "\n",
            "Early stopping at epoch 31\n",
            "Restored model weights from the end of the best epoch: 24\n",
            "--- Training Finished ---\n",
            "\n",
            "--- Starting Comprehensive Evaluation on Test Set ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 129/129 [00:08<00:00, 15.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Top-K Accuracy Results ---\n",
            "Top-1 Accuracy: 33.39%\n",
            "Top-3 Accuracy: 52.24%\n",
            "Top-5 Accuracy: 60.82%\n",
            "\n",
            "--- Additional Performance Metrics ---\n",
            "Macro Average Precision: 0.3255\n",
            "Macro Average Recall: 0.3341\n",
            "Macro Average F1-Score: 0.3272\n",
            "Weighted Average Precision: 0.3283\n",
            "Weighted Average Recall: 0.3339\n",
            "Weighted Average F1-Score: 0.3286\n",
            "\n",
            "--- Model Confidence & Calibration Metrics ---\n",
            "Average Prediction Confidence: 0.4573\n",
            "Confidence Standard Deviation: 0.2411\n",
            "Average Prediction Entropy: 1.9928\n",
            "Expected Calibration Error: 0.1234\n",
            "\n",
            "Final Test Loss: 3.0453\n",
            "===============================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Transformer on ResNet-18 (Learnable PE)"
      ],
      "metadata": {
        "id": "Nvf3HsRLnllh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "CONFIG = {\n",
        "    \"data_path\": \"./tiny-imagenet-200/\",\n",
        "    \"dataset_url\": \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\",\n",
        "    \"batch_size\": 128,\n",
        "    \"num_epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"split_seed\": 42,  # Seed for creating reproducible dataset splits\n",
        "    \"train_split\": 0.70,\n",
        "    \"val_split\": 0.15,\n",
        "    \"test_split\": 0.15,  # Explicitly define test split for clarity\n",
        "    \"num_classes\": 200,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"checkpoint_path\": \"./best_model.pth\",  # Added checkpoint path\n",
        "}\n",
        "\n",
        "# --- Transformer Configuration ---\n",
        "TRANSFORMER_CONFIG = {\n",
        "    \"embedding_dim\": 256,       # Dimension of the tokens fed to the transformer\n",
        "    \"nhead\": 8,                 # Number of attention heads\n",
        "    \"num_encoder_layers\": 3,    # Number of transformer encoder layers\n",
        "    \"dim_feedforward\": 512,     # Hidden dimension in the feed-forward network\n",
        "    \"dropout\": 0.1,\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# Callback Classes\n",
        "# ==========================================\n",
        "\n",
        "class Callback:\n",
        "    \"\"\"Base callback class\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_training_end(self):\n",
        "        pass\n",
        "\n",
        "class ReduceLROnPlateau(Callback):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving\"\"\"\n",
        "    def __init__(self, optimizer, monitor='val_accuracy', factor=0.2, patience=3, min_lr=1e-7, verbose=1):\n",
        "        self.optimizer = optimizer\n",
        "        self.monitor = monitor\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                old_lr = self.optimizer.param_groups[0]['lr']\n",
        "                new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "                if new_lr != old_lr:\n",
        "                    self.optimizer.param_groups[0]['lr'] = new_lr\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nReducing learning rate from {old_lr:.2e} to {new_lr:.2e}\")\n",
        "                    self.wait = 0\n",
        "\n",
        "class EarlyStopping(Callback):\n",
        "    \"\"\"Stop training when a monitored metric has stopped improving\"\"\"\n",
        "    def __init__(self, monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1):\n",
        "        self.monitor = monitor\n",
        "        self.patience = patience\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.best_weights = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None:\n",
        "            return False\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return False\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def on_training_end(self, model=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose:\n",
        "            print(f\"Restored model weights from the end of the best epoch: {self.stopped_epoch + 1 - self.patience}\")\n",
        "        if model is not None and self.restore_best_weights and self.best_weights is not None:\n",
        "            model.load_state_dict(self.best_weights)\n",
        "\n",
        "class ModelCheckpoint(Callback):\n",
        "    \"\"\"Save the model after every epoch\"\"\"\n",
        "    def __init__(self, filepath, save_best_only=True, monitor='val_accuracy', verbose=1):\n",
        "        self.filepath = filepath\n",
        "        self.save_best_only = save_best_only\n",
        "        self.monitor = monitor\n",
        "        self.verbose = verbose\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None or model is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if not self.save_best_only:\n",
        "            filepath = self.filepath.replace('.pth', f'_epoch_{epoch + 1}.pth')\n",
        "            torch.save(model.state_dict(), filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "\n",
        "# ==========================================\n",
        "# Data Preprocessing\n",
        "# ==========================================\n",
        "\n",
        "def download_and_unzip(url, dest_path):\n",
        "    \"\"\"Downloads and unzips with progress and robust error handling.\"\"\"\n",
        "    if os.path.exists(dest_path):\n",
        "        print(\"Dataset directory already exists.\")\n",
        "        return True\n",
        "\n",
        "    zip_path = dest_path.rstrip('/') + \".zip\"\n",
        "    # The parent directory where we will extract the zip file\n",
        "    extract_to_dir = os.path.abspath(os.path.join(dest_path, os.pardir))\n",
        "\n",
        "    print(f\"Downloading dataset from {url}...\")\n",
        "    try:\n",
        "        with requests.get(url, stream=True, timeout=30) as r:\n",
        "            r.raise_for_status()\n",
        "            total_size = int(r.headers.get('content-length', 0))\n",
        "            with open(zip_path, 'wb') as f, tqdm(\n",
        "                total=total_size, unit='iB', unit_scale=True, desc=\"Tiny ImageNet\"\n",
        "            ) as progress_bar:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "                    progress_bar.update(len(chunk))\n",
        "\n",
        "        print(\"Unzipping...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            # **FIX:** Extract to the parent directory to avoid nested folders\n",
        "            zip_ref.extractall(extract_to_dir)\n",
        "        return True\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError downloading file: {e}\", file=sys.stderr)\n",
        "        print(\"Please check your internet connection or the dataset URL.\", file=sys.stderr)\n",
        "        return False\n",
        "\n",
        "    finally:\n",
        "        if os.path.exists(zip_path):\n",
        "            os.remove(zip_path)  # Clean up the zip file\n",
        "\n",
        "def prepare_val_folder(val_dir):\n",
        "    \"\"\"Formats the validation folder to be compatible with ImageFolder.\"\"\"\n",
        "    val_annotations_path = os.path.join(val_dir, 'val_annotations.txt')\n",
        "    if not os.path.exists(val_annotations_path):\n",
        "        return  # Already formatted\n",
        "\n",
        "    print(\"Formatting validation folder...\")\n",
        "    val_img_dir = os.path.join(val_dir, 'images')\n",
        "    val_img_dict = {}\n",
        "    with open(val_annotations_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split('\\t')\n",
        "            img_name, class_id = parts[0], parts[1]\n",
        "            val_img_dict[img_name] = class_id\n",
        "\n",
        "    for img_name, class_id in val_img_dict.items():\n",
        "        class_dir = os.path.join(val_dir, class_id)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        src_path = os.path.join(val_img_dir, img_name)\n",
        "        if os.path.exists(src_path):\n",
        "            shutil.move(src_path, os.path.join(class_dir, img_name))\n",
        "\n",
        "    if os.path.exists(val_annotations_path):\n",
        "        os.remove(val_annotations_path)\n",
        "    if os.path.exists(val_img_dir):\n",
        "        shutil.rmtree(val_img_dir)\n",
        "\n",
        "def get_dataloaders(config):\n",
        "    \"\"\"Downloads, prepares, and splits the data, returning DataLoaders.\"\"\"\n",
        "    if not download_and_unzip(config[\"dataset_url\"], config[\"data_path\"]):\n",
        "        return None  # Return None if download fails\n",
        "\n",
        "    train_dir = os.path.join(config[\"data_path\"], 'train')\n",
        "    val_dir = os.path.join(config[\"data_path\"], 'val')\n",
        "    prepare_val_folder(val_dir)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    train_dataset = ImageFolder(train_dir, transform=transform)\n",
        "    val_dataset_original = ImageFolder(val_dir, transform=transform)\n",
        "    full_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset_original])\n",
        "\n",
        "    # Ensure reproducible splits\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(config[\"train_split\"] * total_size)\n",
        "    val_size = int(config[\"val_split\"] * total_size)\n",
        "    test_size = int(config[\"test_split\"] * total_size)\n",
        "\n",
        "    # Adjust sizes to ensure they sum to total_size (handle rounding issues)\n",
        "    actual_total = train_size + val_size + test_size\n",
        "    if actual_total != total_size:\n",
        "        # Add/subtract the difference to test_size\n",
        "        test_size += (total_size - actual_total)\n",
        "\n",
        "    print(f\"Dataset splits - Train: {train_size}, Val: {val_size}, Test: {test_size}, Total: {total_size}\")\n",
        "\n",
        "    # Create reproducible generator for splitting\n",
        "    generator = torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    train_subset, val_subset, test_subset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size], generator=generator\n",
        "    )\n",
        "\n",
        "    # Set worker init function for reproducible DataLoader behavior\n",
        "    def worker_init_fn(worker_id):\n",
        "        np.random.seed(config[\"split_seed\"] + worker_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# ==========================================\n",
        "# Model Architecture and Training\n",
        "# ==========================================\n",
        "\n",
        "class NonResidualBlock(nn.Module):\n",
        "    \"\"\"A standard convolutional block WITHOUT the residual connection.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(NonResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNetTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    A hybrid architecture combining a non-residual CNN backbone with a Transformer encoder,\n",
        "    including positional embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, block, layers, num_classes, t_config):\n",
        "        super(ResNetTransformer, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.embedding_dim = t_config[\"embedding_dim\"]\n",
        "        self.num_tokens = len(layers) + 1  # 4 layers + 1 initial capture\n",
        "\n",
        "        # 1. CNN Backbone (Feature Extractor)\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        # 2. Projection heads to create tokens from feature maps\n",
        "        self.projections = nn.ModuleList([\n",
        "            self._create_projection(64, self.embedding_dim),\n",
        "            self._create_projection(64, self.embedding_dim),\n",
        "            self._create_projection(128, self.embedding_dim),\n",
        "            self._create_projection(256, self.embedding_dim),\n",
        "            self._create_projection(512, self.embedding_dim)\n",
        "        ])\n",
        "\n",
        "        # 3. Learnable Positional Embedding\n",
        "        self.positional_embedding = nn.Parameter(torch.randn(1, self.num_tokens, self.embedding_dim))\n",
        "\n",
        "        # 4. Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=self.embedding_dim,\n",
        "            nhead=t_config[\"nhead\"],\n",
        "            dim_feedforward=t_config[\"dim_feedforward\"],\n",
        "            dropout=t_config[\"dropout\"],\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=t_config[\"num_encoder_layers\"]\n",
        "        )\n",
        "\n",
        "        # 5. Final Classifier\n",
        "        self.classifier = nn.Linear(self.embedding_dim, num_classes)\n",
        "\n",
        "    def _create_projection(self, in_features, out_features):\n",
        "        return nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, out_features)\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        current_in_channels = self.in_channels\n",
        "        for s in strides:\n",
        "            layers.append(block(current_in_channels, out_channels, s))\n",
        "            current_in_channels = out_channels\n",
        "        self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Pass through CNN backbone and capture features\n",
        "        features = []\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        features.append(x)  # Capture 1: After initial maxpool\n",
        "\n",
        "        x = self.layer1(x); features.append(x)  # Capture 2: After layer1\n",
        "        x = self.layer2(x); features.append(x)  # Capture 3: After layer2\n",
        "        x = self.layer3(x); features.append(x)  # Capture 4: After layer3\n",
        "        x = self.layer4(x); features.append(x)  # Capture 5: After layer4\n",
        "\n",
        "        # 2. Project features to tokens\n",
        "        tokens = [self.projections[i](feature_map) for i, feature_map in enumerate(features)]\n",
        "\n",
        "        # 3. Stack tokens into a sequence\n",
        "        token_sequence = torch.stack(tokens, dim=1)\n",
        "\n",
        "        # 4. Add positional embedding\n",
        "        token_sequence += self.positional_embedding\n",
        "\n",
        "        # 5. Pass through Transformer\n",
        "        transformer_out = self.transformer_encoder(token_sequence)\n",
        "\n",
        "        # 6. Aggregate and classify\n",
        "        aggregated_vector = transformer_out.mean(dim=1)\n",
        "        logits = self.classifier(aggregated_vector)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, config):\n",
        "    \"\"\"Main training loop with callbacks.\"\"\"\n",
        "    device = config[\"device\"]\n",
        "    model.to(device)\n",
        "\n",
        "    # Set seeds for reproducible training\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(config[\"split_seed\"])\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "    # Initialize callbacks\n",
        "    callbacks = [\n",
        "        ReduceLROnPlateau(\n",
        "            optimizer=optimizer,\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=7,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=config[\"checkpoint_path\"],\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        running_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\", leave=False)\n",
        "        for images, labels in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_loss / train_total\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['num_epochs']} | Time: {time.time() - start_time:.2f}s | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Prepare logs for callbacks\n",
        "        logs = {\n",
        "            'train_loss': train_loss,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc\n",
        "        }\n",
        "\n",
        "        # Execute callbacks\n",
        "        for callback in callbacks:\n",
        "            if isinstance(callback, EarlyStopping):\n",
        "                if callback.on_epoch_end(epoch, logs, model):\n",
        "                    early_stop = True\n",
        "                    break\n",
        "            elif isinstance(callback, ModelCheckpoint):\n",
        "                callback.on_epoch_end(epoch, logs, model)\n",
        "            else:\n",
        "                callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    # Execute callback cleanup\n",
        "    for callback in callbacks:\n",
        "        if isinstance(callback, EarlyStopping):\n",
        "            callback.on_training_end(model)\n",
        "        else:\n",
        "            callback.on_training_end()\n",
        "\n",
        "    print(\"--- Training Finished ---\\n\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "\n",
        "def calculate_top_k_accuracy(outputs, labels, k_values=[1, 3, 5]):\n",
        "    \"\"\"Calculate top-k accuracy for given k values.\"\"\"\n",
        "    batch_size = labels.size(0)\n",
        "    _, pred = outputs.topk(max(k_values), 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "    top_k_accuracies = {}\n",
        "    for k in k_values:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        top_k_accuracies[k] = correct_k.item() / batch_size\n",
        "\n",
        "    return top_k_accuracies\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "    \"\"\"Calculate entropy of probability distributions.\"\"\"\n",
        "    # Add small epsilon to avoid log(0)\n",
        "    epsilon = 1e-8\n",
        "    probs = probs + epsilon\n",
        "    entropy = -torch.sum(probs * torch.log(probs), dim=1)\n",
        "    return entropy\n",
        "\n",
        "def calculate_ece(confidences, accuracies, n_bins=10):\n",
        "    \"\"\"Calculate Expected Calibration Error.\"\"\"\n",
        "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers = bin_boundaries[:-1]\n",
        "    bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    ece = 0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower.item()) & (confidences <= bin_upper.item())\n",
        "        prop_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prop_in_bin.item() > 0:\n",
        "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece.item()\n",
        "\n",
        "def comprehensive_evaluation(model, test_loader, criterion, device):\n",
        "    \"\"\"Comprehensive evaluation with all requested metrics.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_confidences = []\n",
        "    all_entropies = []\n",
        "    all_top_k_results = {1: [], 3: [], 5: []}\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Convert outputs to probabilities\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Get predictions and confidences\n",
        "            confidences, predictions = torch.max(probs, dim=1)\n",
        "\n",
        "            # Calculate entropy\n",
        "            entropies = calculate_entropy(probs)\n",
        "\n",
        "            # Calculate top-k accuracies\n",
        "            top_k_accs = calculate_top_k_accuracy(outputs, labels, [1, 3, 5])\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_entropies.extend(entropies.cpu().numpy())\n",
        "\n",
        "            for k in [1, 3, 5]:\n",
        "                all_top_k_results[k].extend([top_k_accs[k]] * labels.size(0))\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_confidences = np.array(all_confidences)\n",
        "    all_entropies = np.array(all_entropies)\n",
        "\n",
        "    # Calculate basic metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    # Calculate top-k accuracies\n",
        "    top1 = np.mean([pred == label for pred, label in zip(all_predictions, all_labels)])\n",
        "    top3 = np.mean(all_top_k_results[3])\n",
        "    top5 = np.mean(all_top_k_results[5])\n",
        "\n",
        "    # Calculate precision, recall, f1-score\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate confidence and calibration metrics\n",
        "    avg_confidence = np.mean(all_confidences)\n",
        "    std_confidence = np.std(all_confidences)\n",
        "    avg_entropy = np.mean(all_entropies)\n",
        "\n",
        "    # Calculate ECE\n",
        "    accuracies = (all_predictions == all_labels).astype(float)\n",
        "    ece = calculate_ece(torch.tensor(all_confidences), torch.tensor(accuracies))\n",
        "\n",
        "    return {\n",
        "        'test_loss': avg_loss,\n",
        "        'top1': top1,\n",
        "        'top3': top3,\n",
        "        'top5': top5,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_weighted': precision_weighted,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'std_confidence': std_confidence,\n",
        "        'avg_entropy': avg_entropy,\n",
        "        'ece': ece\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# Main Execution\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set global seeds for full reproducibility\n",
        "    torch.manual_seed(CONFIG[\"split_seed\"])\n",
        "    np.random.seed(CONFIG[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(CONFIG[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(CONFIG[\"split_seed\"])\n",
        "        # Ensure deterministic behavior on CUDA\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"Using device: {CONFIG['device']}\")\n",
        "    print(f\"Reproducibility seed: {CONFIG['split_seed']}\")\n",
        "\n",
        "    # Get data loaders\n",
        "    dataloaders = get_dataloaders(CONFIG)\n",
        "    if dataloaders is None:\n",
        "        print(\"Could not prepare data. Halting execution.\", file=sys.stderr)\n",
        "        sys.exit(1)  # Exit if data preparation failed\n",
        "\n",
        "    train_loader, val_loader, test_loader = dataloaders\n",
        "\n",
        "    # Initialize and train model with ResNetTransformer\n",
        "    model = ResNetTransformer(\n",
        "        block=NonResidualBlock,\n",
        "        layers=[2, 2, 2, 2],\n",
        "        num_classes=CONFIG[\"num_classes\"],\n",
        "        t_config=TRANSFORMER_CONFIG\n",
        "    )\n",
        "\n",
        "    print(f\"Model has {sum(p.numel() for p in model.parameters())} parameters\")\n",
        "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "    trained_model = train_and_validate(model, train_loader, val_loader, CONFIG)\n",
        "\n",
        "    # Comprehensive evaluation on the test set\n",
        "    print(\"--- Starting Comprehensive Evaluation on Test Set ---\")\n",
        "    results = comprehensive_evaluation(trained_model, test_loader, nn.CrossEntropyLoss(), CONFIG[\"device\"])\n",
        "\n",
        "    # Print all requested metrics\n",
        "    print(\"\\n--- Top-K Accuracy Results ---\")\n",
        "    print(f\"Top-1 Accuracy: {results['top1'] * 100:.2f}%\")\n",
        "    print(f\"Top-3 Accuracy: {results['top3'] * 100:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {results['top5'] * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Additional Performance Metrics ---\")\n",
        "    print(f\"Macro Average Precision: {results['precision_macro']:.4f}\")\n",
        "    print(f\"Macro Average Recall: {results['recall_macro']:.4f}\")\n",
        "    print(f\"Macro Average F1-Score: {results['f1_macro']:.4f}\")\n",
        "    print(f\"Weighted Average Precision: {results['precision_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average Recall: {results['recall_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average F1-Score: {results['f1_weighted']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Model Confidence & Calibration Metrics ---\")\n",
        "    print(f\"Average Prediction Confidence: {results['avg_confidence']:.4f}\")\n",
        "    print(f\"Confidence Standard Deviation: {results['std_confidence']:.4f}\")\n",
        "    print(f\"Average Prediction Entropy: {results['avg_entropy']:.4f}\")\n",
        "    print(f\"Expected Calibration Error: {results['ece']:.4f}\")\n",
        "\n",
        "    print(f\"\\nFinal Test Loss: {results['test_loss']:.4f}\")\n",
        "    print(\"===============================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NpuXkVZnqe5",
        "outputId": "c209faf8-b98d-4df5-85bc-a635689157f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Reproducibility seed: 42\n",
            "Dataset directory already exists.\n",
            "Dataset splits - Train: 77000, Val: 16500, Test: 16500, Total: 110000\n",
            "Model has 12900104 parameters\n",
            "Trainable parameters: 12900104\n",
            "\n",
            "--- Starting Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Time: 57.38s | Train Loss: 4.8858, Train Acc: 2.98% | Val Loss: 4.5156, Val Acc: 5.65%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 | Time: 56.96s | Train Loss: 4.3319, Train Acc: 7.71% | Val Loss: 4.2834, Val Acc: 8.63%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100 | Time: 55.97s | Train Loss: 4.0589, Train Acc: 11.17% | Val Loss: 4.0407, Val Acc: 12.13%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 | Time: 56.58s | Train Loss: 3.8711, Train Acc: 13.77% | Val Loss: 3.8111, Val Acc: 15.13%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100 | Time: 56.66s | Train Loss: 3.7228, Train Acc: 15.74% | Val Loss: 3.7984, Val Acc: 15.27%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 | Time: 56.88s | Train Loss: 3.6071, Train Acc: 17.61% | Val Loss: 3.6304, Val Acc: 17.72%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100 | Time: 58.70s | Train Loss: 3.5116, Train Acc: 19.01% | Val Loss: 3.5444, Val Acc: 18.79%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 | Time: 57.01s | Train Loss: 3.4194, Train Acc: 20.63% | Val Loss: 3.4375, Val Acc: 20.79%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 | Time: 57.93s | Train Loss: 3.3387, Train Acc: 22.04% | Val Loss: 3.3985, Val Acc: 21.70%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 | Time: 57.24s | Train Loss: 3.2655, Train Acc: 23.35% | Val Loss: 3.3036, Val Acc: 23.50%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 | Time: 57.30s | Train Loss: 3.1896, Train Acc: 24.60% | Val Loss: 3.4155, Val Acc: 21.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 | Time: 54.88s | Train Loss: 3.1207, Train Acc: 25.86% | Val Loss: 3.2776, Val Acc: 24.47%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100 | Time: 54.74s | Train Loss: 3.0619, Train Acc: 26.97% | Val Loss: 3.3179, Val Acc: 24.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100 | Time: 54.83s | Train Loss: 3.0029, Train Acc: 28.11% | Val Loss: 3.1880, Val Acc: 26.23%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100 | Time: 55.68s | Train Loss: 2.9450, Train Acc: 29.07% | Val Loss: 3.1501, Val Acc: 26.56%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100 | Time: 54.99s | Train Loss: 2.8991, Train Acc: 29.82% | Val Loss: 3.1747, Val Acc: 26.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100 | Time: 55.25s | Train Loss: 2.8561, Train Acc: 30.95% | Val Loss: 3.0685, Val Acc: 27.82%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100 | Time: 55.52s | Train Loss: 2.8069, Train Acc: 31.97% | Val Loss: 3.1760, Val Acc: 26.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100 | Time: 55.14s | Train Loss: 2.7681, Train Acc: 32.63% | Val Loss: 3.0172, Val Acc: 29.19%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100 | Time: 54.87s | Train Loss: 2.7274, Train Acc: 33.13% | Val Loss: 3.0236, Val Acc: 29.43%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100 | Time: 57.18s | Train Loss: 2.6895, Train Acc: 33.89% | Val Loss: 3.0847, Val Acc: 28.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100 | Time: 55.97s | Train Loss: 2.6575, Train Acc: 34.45% | Val Loss: 2.9994, Val Acc: 30.16%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100 | Time: 57.67s | Train Loss: 2.6177, Train Acc: 35.26% | Val Loss: 3.1152, Val Acc: 28.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/100 | Time: 55.73s | Train Loss: 2.5795, Train Acc: 36.06% | Val Loss: 3.0298, Val Acc: 29.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/100 | Time: 55.43s | Train Loss: 2.5471, Train Acc: 36.73% | Val Loss: 2.9672, Val Acc: 31.32%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100 | Time: 57.04s | Train Loss: 2.5091, Train Acc: 37.59% | Val Loss: 3.0935, Val Acc: 29.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100 | Time: 55.29s | Train Loss: 2.4812, Train Acc: 37.98% | Val Loss: 3.0095, Val Acc: 30.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100 | Time: 55.21s | Train Loss: 2.4541, Train Acc: 38.50% | Val Loss: 3.0848, Val Acc: 30.09%\n",
            "\n",
            "Reducing learning rate from 1.00e-03 to 2.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100 | Time: 56.34s | Train Loss: 2.1303, Train Acc: 45.61% | Val Loss: 2.8647, Val Acc: 34.22%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100 | Time: 55.55s | Train Loss: 2.0564, Train Acc: 47.21% | Val Loss: 2.9102, Val Acc: 34.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100 | Time: 56.13s | Train Loss: 2.0247, Train Acc: 47.82% | Val Loss: 2.9045, Val Acc: 34.30%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100 | Time: 55.28s | Train Loss: 1.9944, Train Acc: 48.44% | Val Loss: 2.9327, Val Acc: 33.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100 | Time: 55.56s | Train Loss: 1.9684, Train Acc: 48.86% | Val Loss: 2.9664, Val Acc: 33.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100 | Time: 56.70s | Train Loss: 1.9476, Train Acc: 49.39% | Val Loss: 2.9740, Val Acc: 34.08%\n",
            "\n",
            "Reducing learning rate from 2.00e-04 to 4.00e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100 | Time: 55.69s | Train Loss: 1.8398, Train Acc: 51.87% | Val Loss: 2.9664, Val Acc: 34.37%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/100 | Time: 55.95s | Train Loss: 1.8250, Train Acc: 52.30% | Val Loss: 2.9828, Val Acc: 34.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/100 | Time: 56.38s | Train Loss: 1.8183, Train Acc: 52.55% | Val Loss: 2.9748, Val Acc: 34.42%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/100 | Time: 55.31s | Train Loss: 1.8119, Train Acc: 52.46% | Val Loss: 2.9912, Val Acc: 34.42%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/100 | Time: 55.38s | Train Loss: 1.8051, Train Acc: 52.81% | Val Loss: 3.0024, Val Acc: 34.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/100 | Time: 56.09s | Train Loss: 1.7951, Train Acc: 53.08% | Val Loss: 3.0141, Val Acc: 34.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/100 | Time: 55.78s | Train Loss: 1.7916, Train Acc: 53.03% | Val Loss: 3.0204, Val Acc: 34.41%\n",
            "\n",
            "Reducing learning rate from 4.00e-05 to 8.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/100 | Time: 55.95s | Train Loss: 1.7643, Train Acc: 53.75% | Val Loss: 3.0177, Val Acc: 34.45%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/100 | Time: 55.24s | Train Loss: 1.7602, Train Acc: 53.73% | Val Loss: 3.0195, Val Acc: 34.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/100 | Time: 54.95s | Train Loss: 1.7569, Train Acc: 54.06% | Val Loss: 3.0262, Val Acc: 34.49%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/100 | Time: 55.98s | Train Loss: 1.7577, Train Acc: 53.96% | Val Loss: 3.0325, Val Acc: 34.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/100 | Time: 56.00s | Train Loss: 1.7594, Train Acc: 53.85% | Val Loss: 3.0287, Val Acc: 34.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/100 | Time: 55.02s | Train Loss: 1.7579, Train Acc: 53.93% | Val Loss: 3.0331, Val Acc: 34.28%\n",
            "\n",
            "Reducing learning rate from 8.00e-06 to 1.60e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/100 | Time: 55.04s | Train Loss: 1.7514, Train Acc: 54.12% | Val Loss: 3.0331, Val Acc: 34.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/100 | Time: 55.79s | Train Loss: 1.7485, Train Acc: 54.13% | Val Loss: 3.0332, Val Acc: 34.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/100 | Time: 55.01s | Train Loss: 1.7458, Train Acc: 54.09% | Val Loss: 3.0292, Val Acc: 34.19%\n",
            "\n",
            "Reducing learning rate from 1.60e-06 to 3.20e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/100 | Time: 56.40s | Train Loss: 1.7511, Train Acc: 54.02% | Val Loss: 3.0348, Val Acc: 34.27%\n",
            "\n",
            "Early stopping at epoch 51\n",
            "Restored model weights from the end of the best epoch: 44\n",
            "--- Training Finished ---\n",
            "\n",
            "--- Starting Comprehensive Evaluation on Test Set ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 129/129 [00:08<00:00, 15.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Top-K Accuracy Results ---\n",
            "Top-1 Accuracy: 34.15%\n",
            "Top-3 Accuracy: 52.64%\n",
            "Top-5 Accuracy: 61.71%\n",
            "\n",
            "--- Additional Performance Metrics ---\n",
            "Macro Average Precision: 0.3345\n",
            "Macro Average Recall: 0.3422\n",
            "Macro Average F1-Score: 0.3352\n",
            "Weighted Average Precision: 0.3371\n",
            "Weighted Average Recall: 0.3415\n",
            "Weighted Average F1-Score: 0.3362\n",
            "\n",
            "--- Model Confidence & Calibration Metrics ---\n",
            "Average Prediction Confidence: 0.5021\n",
            "Confidence Standard Deviation: 0.2522\n",
            "Average Prediction Entropy: 1.8057\n",
            "Expected Calibration Error: 0.1606\n",
            "\n",
            "Final Test Loss: 3.0428\n",
            "===============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Transformer on ResNet-18 (RoPE)"
      ],
      "metadata": {
        "id": "rx0K15J_fSqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "CONFIG = {\n",
        "    \"data_path\": \"./tiny-imagenet-200/\",\n",
        "    \"dataset_url\": \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\",\n",
        "    \"batch_size\": 128,\n",
        "    \"num_epochs\": 100,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"split_seed\": 42,  # Seed for creating reproducible dataset splits\n",
        "    \"train_split\": 0.70,\n",
        "    \"val_split\": 0.15,\n",
        "    \"test_split\": 0.15,  # Explicitly define test split for clarity\n",
        "    \"num_classes\": 200,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"checkpoint_path\": \"./best_model.pth\",  # Added checkpoint path\n",
        "}\n",
        "\n",
        "# --- Transformer Configuration ---\n",
        "TRANSFORMER_CONFIG = {\n",
        "    \"embedding_dim\": 256,\n",
        "    \"nhead\": 8,\n",
        "    \"num_encoder_layers\": 3,\n",
        "    \"dim_feedforward\": 512,\n",
        "    \"dropout\": 0.1,\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# Callback Classes\n",
        "# ==========================================\n",
        "\n",
        "class Callback:\n",
        "    \"\"\"Base callback class\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_training_end(self):\n",
        "        pass\n",
        "\n",
        "class ReduceLROnPlateau(Callback):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving\"\"\"\n",
        "    def __init__(self, optimizer, monitor='val_accuracy', factor=0.2, patience=3, min_lr=1e-7, verbose=1):\n",
        "        self.optimizer = optimizer\n",
        "        self.monitor = monitor\n",
        "        self.factor = factor\n",
        "        self.patience = patience\n",
        "        self.min_lr = min_lr\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                old_lr = self.optimizer.param_groups[0]['lr']\n",
        "                new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "                if new_lr != old_lr:\n",
        "                    self.optimizer.param_groups[0]['lr'] = new_lr\n",
        "                    if self.verbose:\n",
        "                        print(f\"\\nReducing learning rate from {old_lr:.2e} to {new_lr:.2e}\")\n",
        "                    self.wait = 0\n",
        "\n",
        "class EarlyStopping(Callback):\n",
        "    \"\"\"Stop training when a monitored metric has stopped improving\"\"\"\n",
        "    def __init__(self, monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1):\n",
        "        self.monitor = monitor\n",
        "        self.patience = patience\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.verbose = verbose\n",
        "        self.wait = 0\n",
        "        self.best = None\n",
        "        self.best_weights = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None:\n",
        "            return False\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return False\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "            return False\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            if model is not None and self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def on_training_end(self, model=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose:\n",
        "            print(f\"Restored model weights from the end of the best epoch: {self.stopped_epoch + 1 - self.patience}\")\n",
        "        if model is not None and self.restore_best_weights and self.best_weights is not None:\n",
        "            model.load_state_dict(self.best_weights)\n",
        "\n",
        "class ModelCheckpoint(Callback):\n",
        "    \"\"\"Save the model after every epoch\"\"\"\n",
        "    def __init__(self, filepath, save_best_only=True, monitor='val_accuracy', verbose=1):\n",
        "        self.filepath = filepath\n",
        "        self.save_best_only = save_best_only\n",
        "        self.monitor = monitor\n",
        "        self.verbose = verbose\n",
        "        self.best = None\n",
        "        self.mode = 'min' if 'loss' in monitor else 'max'\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None, model=None):\n",
        "        if logs is None or model is None:\n",
        "            return\n",
        "\n",
        "        current = logs.get(self.monitor)\n",
        "        if current is None:\n",
        "            return\n",
        "\n",
        "        if not self.save_best_only:\n",
        "            filepath = self.filepath.replace('.pth', f'_epoch_{epoch + 1}.pth')\n",
        "            torch.save(model.state_dict(), filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.best is None:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "            return\n",
        "\n",
        "        if self.mode == 'min':\n",
        "            improved = current < self.best\n",
        "        else:\n",
        "            improved = current > self.best\n",
        "\n",
        "        if improved:\n",
        "            self.best = current\n",
        "            torch.save(model.state_dict(), self.filepath)\n",
        "            if self.verbose:\n",
        "                print(f\"\\nModel saved to {self.filepath}\")\n",
        "\n",
        "# ==========================================\n",
        "# Data Preprocessing\n",
        "# ==========================================\n",
        "\n",
        "def download_and_unzip(url, dest_path):\n",
        "    \"\"\"Downloads and unzips with progress and robust error handling.\"\"\"\n",
        "    if os.path.exists(dest_path):\n",
        "        print(\"Dataset directory already exists.\")\n",
        "        return True\n",
        "\n",
        "    zip_path = dest_path.rstrip('/') + \".zip\"\n",
        "    # The parent directory where we will extract the zip file\n",
        "    extract_to_dir = os.path.abspath(os.path.join(dest_path, os.pardir))\n",
        "\n",
        "    print(f\"Downloading dataset from {url}...\")\n",
        "    try:\n",
        "        with requests.get(url, stream=True, timeout=30) as r:\n",
        "            r.raise_for_status()\n",
        "            total_size = int(r.headers.get('content-length', 0))\n",
        "            with open(zip_path, 'wb') as f, tqdm(\n",
        "                total=total_size, unit='iB', unit_scale=True, desc=\"Tiny ImageNet\"\n",
        "            ) as progress_bar:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "                    progress_bar.update(len(chunk))\n",
        "\n",
        "        print(\"Unzipping...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to_dir)\n",
        "        return True\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError downloading file: {e}\", file=sys.stderr)\n",
        "        print(\"Please check your internet connection or the dataset URL.\", file=sys.stderr)\n",
        "        return False\n",
        "\n",
        "    finally:\n",
        "        if os.path.exists(zip_path):\n",
        "            os.remove(zip_path)  # Clean up the zip file\n",
        "\n",
        "def prepare_val_folder(val_dir):\n",
        "    \"\"\"Formats the validation folder to be compatible with ImageFolder.\"\"\"\n",
        "    val_annotations_path = os.path.join(val_dir, 'val_annotations.txt')\n",
        "    if not os.path.exists(val_annotations_path):\n",
        "        return  # Already formatted\n",
        "\n",
        "    print(\"Formatting validation folder...\")\n",
        "    val_img_dir = os.path.join(val_dir, 'images')\n",
        "    val_img_dict = {}\n",
        "    with open(val_annotations_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split('\\t')\n",
        "            img_name, class_id = parts[0], parts[1]\n",
        "            val_img_dict[img_name] = class_id\n",
        "\n",
        "    for img_name, class_id in val_img_dict.items():\n",
        "        class_dir = os.path.join(val_dir, class_id)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        src_path = os.path.join(val_img_dir, img_name)\n",
        "        if os.path.exists(src_path):\n",
        "            shutil.move(src_path, os.path.join(class_dir, img_name))\n",
        "\n",
        "    if os.path.exists(val_annotations_path):\n",
        "        os.remove(val_annotations_path)\n",
        "    if os.path.exists(val_img_dir):\n",
        "        shutil.rmtree(val_img_dir)\n",
        "\n",
        "def get_dataloaders(config):\n",
        "    \"\"\"Downloads, prepares, and splits the data, returning DataLoaders.\"\"\"\n",
        "    if not download_and_unzip(config[\"dataset_url\"], config[\"data_path\"]):\n",
        "        return None  # Return None if download fails\n",
        "\n",
        "    train_dir = os.path.join(config[\"data_path\"], 'train')\n",
        "    val_dir = os.path.join(config[\"data_path\"], 'val')\n",
        "    prepare_val_folder(val_dir)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    train_dataset = ImageFolder(train_dir, transform=transform)\n",
        "    val_dataset_original = ImageFolder(val_dir, transform=transform)\n",
        "    full_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset_original])\n",
        "\n",
        "    # Ensure reproducible splits\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(config[\"train_split\"] * total_size)\n",
        "    val_size = int(config[\"val_split\"] * total_size)\n",
        "    test_size = int(config[\"test_split\"] * total_size)\n",
        "\n",
        "    # Adjust sizes to ensure they sum to total_size (handle rounding issues)\n",
        "    actual_total = train_size + val_size + test_size\n",
        "    if actual_total != total_size:\n",
        "        test_size += (total_size - actual_total)\n",
        "\n",
        "    print(f\"Dataset splits - Train: {train_size}, Val: {val_size}, Test: {test_size}, Total: {total_size}\")\n",
        "\n",
        "    # Create reproducible generator for splitting\n",
        "    generator = torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    train_subset, val_subset, test_subset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size], generator=generator\n",
        "    )\n",
        "\n",
        "    # Set worker init function for reproducible DataLoader behavior\n",
        "    def worker_init_fn(worker_id):\n",
        "        np.random.seed(config[\"split_seed\"] + worker_id)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn,\n",
        "        generator=torch.Generator().manual_seed(config[\"split_seed\"])\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_subset,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# ==========================================\n",
        "# Model Architecture and Training\n",
        "# ==========================================\n",
        "\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    The Rotary Positional Embedding (RoPE) module.\n",
        "    This implementation is based on the paper \"RoFormer: Enhanced Transformer with Rotary Position Embedding\".\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, base=10000):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.base = base\n",
        "        # Create inverse frequencies and register as a buffer\n",
        "        inv_freq = 1.0 / (self.base ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        self.register_buffer(\"inv_freq\", inv_freq)\n",
        "        self.seq_len_cached = None\n",
        "        self.cos_cached = None\n",
        "        self.sin_cached = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.shape[1]\n",
        "        # Check if we need to recompute the cache\n",
        "        if seq_len != self.seq_len_cached:\n",
        "            self.seq_len_cached = seq_len\n",
        "            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)\n",
        "            freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
        "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n",
        "            self.cos_cached = emb.cos()[:, None, :]\n",
        "            self.sin_cached = emb.sin()[:, None, :]\n",
        "\n",
        "        # Apply the rotation\n",
        "        return self.cos_cached, self.sin_cached\n",
        "\n",
        "def rotate_half(x):\n",
        "    x1, x2 = x[..., : x.shape[-1] // 2], x[..., x.shape[-1] // 2 :]\n",
        "    return torch.cat((-x2, x1), dim=x1.ndim - 1)\n",
        "\n",
        "def apply_rotary_pos_emb(q, k, cos, sin):\n",
        "    return (q * cos) + (rotate_half(q) * sin), (k * cos) + (rotate_half(k) * sin)\n",
        "\n",
        "class MultiHeadAttentionWithRoPE(nn.Module):\n",
        "    \"\"\"Custom Multi-Head Attention with RoPE support\"\"\"\n",
        "    def __init__(self, d_model, nhead, dropout=0.1, batch_first=True):\n",
        "        super().__init__()\n",
        "        assert d_model % nhead == 0\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.d_k = d_model // nhead\n",
        "        self.batch_first = batch_first  # Add this attribute\n",
        "\n",
        "        self.w_q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.w_k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.w_v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.rotary_emb = RotaryEmbedding(self.d_k)\n",
        "\n",
        "    def forward(self, query, key, value, key_padding_mask=None, attn_mask=None, need_weights=False, is_causal=False):\n",
        "        batch_size, seq_len, _ = query.size()\n",
        "\n",
        "        # Linear transformations\n",
        "        Q = self.w_q(query)  # [batch_size, seq_len, d_model]\n",
        "        K = self.w_k(key)    # [batch_size, seq_len, d_model]\n",
        "        V = self.w_v(value)  # [batch_size, seq_len, d_model]\n",
        "\n",
        "        # Reshape for multi-head attention\n",
        "        Q = Q.view(batch_size, seq_len, self.nhead, self.d_k)  # [batch, seq, heads, d_k]\n",
        "        K = K.view(batch_size, seq_len, self.nhead, self.d_k)\n",
        "        V = V.view(batch_size, seq_len, self.nhead, self.d_k)\n",
        "\n",
        "        # Apply RoPE to Q and K\n",
        "        cos, sin = self.rotary_emb(query)\n",
        "        Q, K = apply_rotary_pos_emb(Q, K, cos, sin)\n",
        "\n",
        "        # Transpose for attention computation: [batch, heads, seq, d_k]\n",
        "        Q = Q.transpose(1, 2)\n",
        "        K = K.transpose(1, 2)\n",
        "        V = V.transpose(1, 2)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # Apply masks if provided\n",
        "        if attn_mask is not None:\n",
        "            scores = scores.masked_fill(attn_mask == 0, -1e9)\n",
        "\n",
        "        if key_padding_mask is not None:\n",
        "            # key_padding_mask: [batch_size, seq_len], True for padding positions\n",
        "            key_padding_mask = key_padding_mask.unsqueeze(1).unsqueeze(2)  # [batch, 1, 1, seq]\n",
        "            scores = scores.masked_fill(key_padding_mask, -1e9)\n",
        "\n",
        "        attention_weights = torch.softmax(scores, dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "        # Apply attention to values\n",
        "        attention_output = torch.matmul(attention_weights, V)  # [batch, heads, seq, d_k]\n",
        "\n",
        "        # Concatenate heads\n",
        "        attention_output = attention_output.transpose(1, 2).contiguous().view(\n",
        "            batch_size, seq_len, self.d_model\n",
        "        )\n",
        "\n",
        "        # Final linear transformation\n",
        "        output = self.w_o(attention_output)\n",
        "\n",
        "        if need_weights:\n",
        "            return output, attention_weights.mean(dim=1)  # Average over heads for compatibility\n",
        "        return output\n",
        "\n",
        "class TransformerEncoderLayerWithRoPE(nn.Module):\n",
        "    \"\"\"\n",
        "    A custom Transformer Encoder Layer that incorporates RoPE.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, nhead, dim_feedforward, dropout, batch_first=True):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttentionWithRoPE(d_model, nhead, dropout, batch_first)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        self.batch_first = batch_first  # Add this attribute\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n",
        "        # Self-attention with RoPE\n",
        "        src2 = self.self_attn(src, src, src, key_padding_mask=src_key_padding_mask, attn_mask=src_mask)\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "\n",
        "        # Feed Forward\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src\n",
        "\n",
        "class NonResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(NonResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNetTransformer(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes, t_config):\n",
        "        super(ResNetTransformer, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.embedding_dim = t_config[\"embedding_dim\"]\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.projections = nn.ModuleList([\n",
        "            self._create_projection(64, self.embedding_dim),\n",
        "            self._create_projection(64, self.embedding_dim),\n",
        "            self._create_projection(128, self.embedding_dim),\n",
        "            self._create_projection(256, self.embedding_dim),\n",
        "            self._create_projection(512, self.embedding_dim)\n",
        "        ])\n",
        "\n",
        "        # Create transformer encoder layers manually\n",
        "        self.transformer_layers = nn.ModuleList([\n",
        "            TransformerEncoderLayerWithRoPE(\n",
        "                d_model=self.embedding_dim,\n",
        "                nhead=t_config[\"nhead\"],\n",
        "                dim_feedforward=t_config[\"dim_feedforward\"],\n",
        "                dropout=t_config[\"dropout\"],\n",
        "                batch_first=True\n",
        "            ) for _ in range(t_config[\"num_encoder_layers\"])\n",
        "        ])\n",
        "\n",
        "        self.classifier = nn.Linear(self.embedding_dim, num_classes)\n",
        "\n",
        "    def _create_projection(self, in_features, out_features):\n",
        "        return nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, out_features)\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        current_in_channels = self.in_channels\n",
        "        for s in strides:\n",
        "            layers.append(block(current_in_channels, out_channels, s))\n",
        "            current_in_channels = out_channels\n",
        "        self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = []\n",
        "        x = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
        "        features.append(x)\n",
        "        x = self.layer1(x)\n",
        "        features.append(x)\n",
        "        x = self.layer2(x)\n",
        "        features.append(x)\n",
        "        x = self.layer3(x)\n",
        "        features.append(x)\n",
        "        x = self.layer4(x)\n",
        "        features.append(x)\n",
        "\n",
        "        tokens = [self.projections[i](feat) for i, feat in enumerate(features)]\n",
        "        token_sequence = torch.stack(tokens, dim=1)\n",
        "\n",
        "        # Apply transformer layers manually\n",
        "        for layer in self.transformer_layers:\n",
        "            token_sequence = layer(token_sequence)\n",
        "\n",
        "        aggregated_vector = token_sequence.mean(dim=1)\n",
        "        logits = self.classifier(aggregated_vector)\n",
        "        return logits\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, config):\n",
        "    \"\"\"Main training loop with callbacks.\"\"\"\n",
        "    device = config[\"device\"]\n",
        "    model.to(device)\n",
        "\n",
        "    # Set seeds for reproducible training\n",
        "    torch.manual_seed(config[\"split_seed\"])\n",
        "    np.random.seed(config[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(config[\"split_seed\"])\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "    # Initialize callbacks\n",
        "    callbacks = [\n",
        "        ReduceLROnPlateau(\n",
        "            optimizer=optimizer,\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=7,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            filepath=config[\"checkpoint_path\"],\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    early_stop = False\n",
        "\n",
        "    for epoch in range(config[\"num_epochs\"]):\n",
        "        if early_stop:\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        running_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']} [Train]\", leave=False)\n",
        "        for images, labels in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_loss / train_total\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['num_epochs']} | Time: {time.time() - start_time:.2f}s | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Prepare logs for callbacks\n",
        "        logs = {\n",
        "            'train_loss': train_loss,\n",
        "            'train_accuracy': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc\n",
        "        }\n",
        "\n",
        "        # Execute callbacks\n",
        "        for callback in callbacks:\n",
        "            if isinstance(callback, EarlyStopping):\n",
        "                if callback.on_epoch_end(epoch, logs, model):\n",
        "                    early_stop = True\n",
        "                    break\n",
        "            elif isinstance(callback, ModelCheckpoint):\n",
        "                callback.on_epoch_end(epoch, logs, model)\n",
        "            else:\n",
        "                callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    # Execute callback cleanup\n",
        "    for callback in callbacks:\n",
        "        if isinstance(callback, EarlyStopping):\n",
        "            callback.on_training_end(model)\n",
        "        else:\n",
        "            callback.on_training_end()\n",
        "\n",
        "    print(\"--- Training Finished ---\\n\")\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# Evaluation\n",
        "# ==========================================\n",
        "\n",
        "def calculate_top_k_accuracy(outputs, labels, k_values=[1, 3, 5]):\n",
        "    \"\"\"Calculate top-k accuracy for given k values.\"\"\"\n",
        "    batch_size = labels.size(0)\n",
        "    _, pred = outputs.topk(max(k_values), 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
        "\n",
        "    top_k_accuracies = {}\n",
        "    for k in k_values:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        top_k_accuracies[k] = correct_k.item() / batch_size\n",
        "\n",
        "    return top_k_accuracies\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "    \"\"\"Calculate entropy of probability distributions.\"\"\"\n",
        "    # Add small epsilon to avoid log(0)\n",
        "    epsilon = 1e-8\n",
        "    probs = probs + epsilon\n",
        "    entropy = -torch.sum(probs * torch.log(probs), dim=1)\n",
        "    return entropy\n",
        "\n",
        "def calculate_ece(confidences, accuracies, n_bins=10):\n",
        "    \"\"\"Calculate Expected Calibration Error.\"\"\"\n",
        "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "    bin_lowers = bin_boundaries[:-1]\n",
        "    bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    ece = 0\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        in_bin = (confidences > bin_lower.item()) & (confidences <= bin_upper.item())\n",
        "        prop_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prop_in_bin.item() > 0:\n",
        "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece.item()\n",
        "\n",
        "def comprehensive_evaluation(model, test_loader, criterion, device):\n",
        "    \"\"\"Comprehensive evaluation with all requested metrics.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_confidences = []\n",
        "    all_entropies = []\n",
        "    all_top_k_results = {1: [], 3: [], 5: []}\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Convert outputs to probabilities\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Get predictions and confidences\n",
        "            confidences, predictions = torch.max(probs, dim=1)\n",
        "\n",
        "            # Calculate entropy\n",
        "            entropies = calculate_entropy(probs)\n",
        "\n",
        "            # Calculate top-k accuracies\n",
        "            top_k_accs = calculate_top_k_accuracy(outputs, labels, [1, 3, 5])\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_confidences.extend(confidences.cpu().numpy())\n",
        "            all_entropies.extend(entropies.cpu().numpy())\n",
        "\n",
        "            for k in [1, 3, 5]:\n",
        "                all_top_k_results[k].extend([top_k_accs[k]] * labels.size(0))\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_confidences = np.array(all_confidences)\n",
        "    all_entropies = np.array(all_entropies)\n",
        "\n",
        "    # Calculate basic metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "\n",
        "    # Calculate top-k accuracies\n",
        "    top1 = np.mean([pred == label for pred, label in zip(all_predictions, all_labels)])\n",
        "    top3 = np.mean(all_top_k_results[3])\n",
        "    top5 = np.mean(all_top_k_results[5])\n",
        "\n",
        "    # Calculate precision, recall, f1-score\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "        all_labels, all_predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Calculate confidence and calibration metrics\n",
        "    avg_confidence = np.mean(all_confidences)\n",
        "    std_confidence = np.std(all_confidences)\n",
        "    avg_entropy = np.mean(all_entropies)\n",
        "\n",
        "    # Calculate ECE\n",
        "    accuracies = (all_predictions == all_labels).astype(float)\n",
        "    ece = calculate_ece(torch.tensor(all_confidences), torch.tensor(accuracies))\n",
        "\n",
        "    return {\n",
        "        'test_loss': avg_loss,\n",
        "        'top1': top1,\n",
        "        'top3': top3,\n",
        "        'top5': top5,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_weighted': precision_weighted,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'avg_confidence': avg_confidence,\n",
        "        'std_confidence': std_confidence,\n",
        "        'avg_entropy': avg_entropy,\n",
        "        'ece': ece\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# Main Execution\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Set global seeds for full reproducibility\n",
        "    torch.manual_seed(CONFIG[\"split_seed\"])\n",
        "    np.random.seed(CONFIG[\"split_seed\"])\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(CONFIG[\"split_seed\"])\n",
        "        torch.cuda.manual_seed_all(CONFIG[\"split_seed\"])\n",
        "        # Ensure deterministic behavior on CUDA\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    print(f\"Using device: {CONFIG['device']}\")\n",
        "    print(f\"Reproducibility seed: {CONFIG['split_seed']}\")\n",
        "\n",
        "    # Get data loaders\n",
        "    dataloaders = get_dataloaders(CONFIG)\n",
        "    if dataloaders is None:\n",
        "        print(\"Could not prepare data. Halting execution.\", file=sys.stderr)\n",
        "        sys.exit(1)  # Exit if data preparation failed\n",
        "\n",
        "    train_loader, val_loader, test_loader = dataloaders\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = ResNetTransformer(\n",
        "        block=NonResidualBlock,\n",
        "        layers=[2, 2, 2, 2],\n",
        "        num_classes=CONFIG[\"num_classes\"],\n",
        "        t_config=TRANSFORMER_CONFIG\n",
        "    )\n",
        "    trained_model = train_and_validate(model, train_loader, val_loader, CONFIG)\n",
        "\n",
        "    # Comprehensive evaluation on the test set\n",
        "    print(\"--- Starting Comprehensive Evaluation on Test Set ---\")\n",
        "    results = comprehensive_evaluation(trained_model, test_loader, nn.CrossEntropyLoss(), CONFIG[\"device\"])\n",
        "\n",
        "    # Print all requested metrics\n",
        "    print(\"\\n--- Top-K Accuracy Results ---\")\n",
        "    print(f\"Top-1 Accuracy: {results['top1'] * 100:.2f}%\")\n",
        "    print(f\"Top-3 Accuracy: {results['top3'] * 100:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {results['top5'] * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\n--- Additional Performance Metrics ---\")\n",
        "    print(f\"Macro Average Precision: {results['precision_macro']:.4f}\")\n",
        "    print(f\"Macro Average Recall: {results['recall_macro']:.4f}\")\n",
        "    print(f\"Macro Average F1-Score: {results['f1_macro']:.4f}\")\n",
        "    print(f\"Weighted Average Precision: {results['precision_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average Recall: {results['recall_weighted']:.4f}\")\n",
        "    print(f\"Weighted Average F1-Score: {results['f1_weighted']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Model Confidence & Calibration Metrics ---\")\n",
        "    print(f\"Average Prediction Confidence: {results['avg_confidence']:.4f}\")\n",
        "    print(f\"Confidence Standard Deviation: {results['std_confidence']:.4f}\")\n",
        "    print(f\"Average Prediction Entropy: {results['avg_entropy']:.4f}\")\n",
        "    print(f\"Expected Calibration Error: {results['ece']:.4f}\")\n",
        "\n",
        "    print(f\"\\nFinal Test Loss: {results['test_loss']:.4f}\")\n",
        "    print(\"===============================================\")"
      ],
      "metadata": {
        "id": "BjrC7Lb5uIPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d867e0-d9ec-4b0b-9c3e-2eeb31eb6549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Reproducibility seed: 42\n",
            "Downloading dataset from http://cs231n.stanford.edu/tiny-imagenet-200.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tiny ImageNet: 100%|██████████| 248M/248M [00:25<00:00, 9.70MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping...\n",
            "Formatting validation folder...\n",
            "Dataset splits - Train: 77000, Val: 16500, Test: 16500, Total: 110000\n",
            "\n",
            "--- Starting Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Time: 60.55s | Train Loss: 4.6645, Train Acc: 4.95% | Val Loss: 4.2716, Val Acc: 8.33%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 | Time: 57.77s | Train Loss: 4.0776, Train Acc: 10.82% | Val Loss: 3.9235, Val Acc: 13.03%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100 | Time: 57.42s | Train Loss: 3.7706, Train Acc: 15.49% | Val Loss: 3.7226, Val Acc: 16.55%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 | Time: 57.51s | Train Loss: 3.5552, Train Acc: 18.93% | Val Loss: 3.5902, Val Acc: 19.30%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100 | Time: 56.57s | Train Loss: 3.3872, Train Acc: 21.74% | Val Loss: 3.4518, Val Acc: 21.18%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 | Time: 56.57s | Train Loss: 3.2484, Train Acc: 24.31% | Val Loss: 3.3680, Val Acc: 22.65%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100 | Time: 56.71s | Train Loss: 3.1402, Train Acc: 26.36% | Val Loss: 3.2524, Val Acc: 24.76%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 | Time: 56.11s | Train Loss: 3.0445, Train Acc: 28.03% | Val Loss: 3.1008, Val Acc: 27.65%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 | Time: 57.22s | Train Loss: 2.9604, Train Acc: 29.43% | Val Loss: 3.0473, Val Acc: 28.46%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 | Time: 56.78s | Train Loss: 2.8796, Train Acc: 31.11% | Val Loss: 3.0805, Val Acc: 28.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 | Time: 58.34s | Train Loss: 2.8078, Train Acc: 32.62% | Val Loss: 3.0366, Val Acc: 29.18%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 | Time: 58.39s | Train Loss: 2.7410, Train Acc: 33.67% | Val Loss: 3.0729, Val Acc: 29.58%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100 | Time: 58.23s | Train Loss: 2.6813, Train Acc: 34.74% | Val Loss: 3.0411, Val Acc: 30.50%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100 | Time: 56.43s | Train Loss: 2.6253, Train Acc: 35.90% | Val Loss: 2.9692, Val Acc: 31.07%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100 | Time: 57.44s | Train Loss: 2.5626, Train Acc: 37.05% | Val Loss: 2.9295, Val Acc: 32.22%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100 | Time: 56.82s | Train Loss: 2.5182, Train Acc: 37.88% | Val Loss: 2.9728, Val Acc: 31.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100 | Time: 58.37s | Train Loss: 2.4728, Train Acc: 38.88% | Val Loss: 2.8813, Val Acc: 32.52%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100 | Time: 57.14s | Train Loss: 2.4268, Train Acc: 39.81% | Val Loss: 2.8642, Val Acc: 32.82%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100 | Time: 57.64s | Train Loss: 2.3776, Train Acc: 40.83% | Val Loss: 2.8674, Val Acc: 33.66%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100 | Time: 57.06s | Train Loss: 2.3384, Train Acc: 41.47% | Val Loss: 2.8855, Val Acc: 33.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100 | Time: 58.11s | Train Loss: 2.2981, Train Acc: 42.30% | Val Loss: 2.8658, Val Acc: 34.30%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100 | Time: 57.19s | Train Loss: 2.2504, Train Acc: 43.17% | Val Loss: 2.8709, Val Acc: 34.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100 | Time: 58.30s | Train Loss: 2.2124, Train Acc: 44.09% | Val Loss: 2.8842, Val Acc: 33.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/100 | Time: 57.14s | Train Loss: 2.1763, Train Acc: 44.55% | Val Loss: 2.8612, Val Acc: 34.35%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/100 | Time: 58.26s | Train Loss: 2.1434, Train Acc: 45.14% | Val Loss: 2.9040, Val Acc: 34.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100 | Time: 57.44s | Train Loss: 2.0981, Train Acc: 46.28% | Val Loss: 2.9893, Val Acc: 33.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100 | Time: 57.28s | Train Loss: 2.0647, Train Acc: 46.81% | Val Loss: 2.9261, Val Acc: 34.35%\n",
            "\n",
            "Reducing learning rate from 1.00e-03 to 2.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100 | Time: 57.69s | Train Loss: 1.6809, Train Acc: 56.13% | Val Loss: 2.7975, Val Acc: 38.16%\n",
            "\n",
            "Model saved to ./best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100 | Time: 56.98s | Train Loss: 1.5801, Train Acc: 58.33% | Val Loss: 2.8540, Val Acc: 37.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100 | Time: 57.67s | Train Loss: 1.5274, Train Acc: 59.53% | Val Loss: 2.9179, Val Acc: 37.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100 | Time: 56.86s | Train Loss: 1.4863, Train Acc: 60.53% | Val Loss: 2.9663, Val Acc: 37.27%\n",
            "\n",
            "Reducing learning rate from 2.00e-04 to 4.00e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100 | Time: 58.22s | Train Loss: 1.3576, Train Acc: 63.78% | Val Loss: 2.9652, Val Acc: 37.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100 | Time: 57.43s | Train Loss: 1.3328, Train Acc: 64.48% | Val Loss: 2.9880, Val Acc: 37.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100 | Time: 58.39s | Train Loss: 1.3251, Train Acc: 64.68% | Val Loss: 3.0134, Val Acc: 37.61%\n",
            "\n",
            "Reducing learning rate from 4.00e-05 to 8.00e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100 | Time: 57.51s | Train Loss: 1.2946, Train Acc: 65.56% | Val Loss: 3.0092, Val Acc: 37.56%\n",
            "\n",
            "Early stopping at epoch 35\n",
            "Restored model weights from the end of the best epoch: 28\n",
            "--- Training Finished ---\n",
            "\n",
            "--- Starting Comprehensive Evaluation on Test Set ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 129/129 [00:08<00:00, 14.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Top-K Accuracy Results ---\n",
            "Top-1 Accuracy: 37.86%\n",
            "Top-3 Accuracy: 56.63%\n",
            "Top-5 Accuracy: 65.21%\n",
            "\n",
            "--- Additional Performance Metrics ---\n",
            "Macro Average Precision: 0.3731\n",
            "Macro Average Recall: 0.3780\n",
            "Macro Average F1-Score: 0.3733\n",
            "Weighted Average Precision: 0.3760\n",
            "Weighted Average Recall: 0.3786\n",
            "Weighted Average F1-Score: 0.3751\n",
            "\n",
            "--- Model Confidence & Calibration Metrics ---\n",
            "Average Prediction Confidence: 0.5694\n",
            "Confidence Standard Deviation: 0.2576\n",
            "Average Prediction Entropy: 1.5253\n",
            "Expected Calibration Error: 0.1908\n",
            "\n",
            "Final Test Loss: 2.9821\n",
            "===============================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}